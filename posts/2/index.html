<!DOCTYPE html>
<html lang="en">
<!--.  ,--,                          ,-. ,-.
 |  | /  /                         __| |_| |
 |  |/  / _ __ _   _ ____ _   _ _ (__, ._| |___
 |      \| `__| | | Y ___| |_| | `_  \ | | ,_. \
 |  |\   \ |  | |_| |___ \___, | | | | | | | | |
 |__| \___\|  '.__,_|____/ __| |_| |_|_| |_| |_|
                          '----><head>
 <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Page 2 of 5 for posts | Bill Hunt</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="posts" />
<meta name="author" content="Bill Hunt" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Personal website and blog of Bill Hunt" />
<meta property="og:description" content="Personal website and blog of Bill Hunt" />
<link rel="canonical" href="https://billhunt.dev/posts/2/" />
<meta property="og:url" content="https://billhunt.dev/posts/2/" />
<meta property="og:site_name" content="Bill Hunt" />
<meta property="og:type" content="website" />
<link rel="prev" href="https://billhunt.dev/posts/" />
<link rel="next" href="https://billhunt.dev/posts/3/" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="posts" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Bill Hunt"},"description":"Personal website and blog of Bill Hunt","headline":"posts","url":"https://billhunt.dev/posts/2/"}</script>
<!-- End Jekyll SEO tag -->

  <link rel="stylesheet" href="/assets/css/main.css?1717012122">
  <link rel="stylesheet" media="print" href="/assets/css/print.css?1717012122">

  <link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml" />
  <link rel="alternate" type="application/atom+xml" title=" - Posts" href="https://billhunt.dev/feed.xml" />
  <link rel="alternate" type="application/atom+xml" title=" - Featured Jobs " href="https://billhunt.dev/jobs.xml" />
  <link rel="alternate" type="application/atom+xml" title=" - USAJobs List" href="https://billhunt.dev/jobs.xml" />
  <link rel="alternate" type="application/atom+xml" title="Enderprise Architecture YouTube Series" href="https://www.youtube.com/feeds/videos.xml?channel_id=UCSL7BIdwgBEZ09BpD9xPPYQ">
  <link rel="meta" type="application/rdf+xml" title="FOAF" href="https://billhunt.dev/foaf.rdf" />
  

  <link rel="me" href="https://mastodon.publicinterest.town/@krusynth" />
  <link rel="me" href="https://mastodon.cloud/@krusynth" />

  <script src="https://static.billhunt.dev/js/jquery.min.js?1717012122"></script>
  <script src="https://static.billhunt.dev/assets/js/unpoly.min.js?1717012122"></script>
  <script src="https://static.billhunt.dev/assets/js/fontawesome-6/fontawesome.min.js?1717012122"></script>
  <script type="module" src="/assets/js/main.js?1717012122"></script>
  <script src="/assets/js/search.js?1717012122"></script>
  <script src="/assets/js/jobs.js?1717012122"></script>
  <script src="https://static.billhunt.dev/assets/js/blink-polyfill.js"></script>
</head>
<body><nav class="navbar navbar-expand-lg container">
  <div class="branding">
    <a class="navbar-brand" rel="author" href="/" title="Bill Hunt | Home" up-follow>Bill Hunt</a>
    <div class="about-description">
      U.S. Gov Civic Technologist & Policy Expert
    </div>
  </div>

  <div class="navlink-container">
    <ul class="nav navbar-nav nav-pages">
      <li class="nav-item nav-page nav-search" id="nav-search">
        <a class="nav-link" href="/search/" title="Search" up-follow><span class="fa-magnifying-glass fas"></span></a>
      </li>
      <li class="nav-item nav-page">
        <a class="nav-link" href="/blog/" up-follow>Blog</a>
      </li>
      <li class="nav-item nav-page">
        <a class="nav-link" href="/about/" up-follow>About</a>
      </li>
      <li class="nav-item nav-page">
        <a class="nav-link" href="/shop/" up-follow>Shop</a>
      </li>
       <li class="nav-item nav-page">
        <a class="nav-link" href="/jobs/" up-follow>Jobs</a>
      </li>
      <li class="nav-item nav-page">
        <a class="nav-link" href="/links/" up-follow>Links</a>
      </li>
      <li class="mastodon nav-item nav-social">
        <a href="https://mastodon.publicinterest.town/@krusynth" title="Mastodon" class="nav-link" rel="me"><span class="fab fa-mastodon icon"></span></a>
      </li>
        
      <li class="github nav-item nav-social">
        <a href="https://github.com/krusynth" title="GitHub" class="nav-link" rel="me"><span class="fab fa-github icon"></span></a>
      </li>
        
      <li class="linkedin nav-item nav-social">
        <a href="https://www.linkedin.com/in/krusynth/" title="LinkedIn" class="nav-link" rel="me"><span class="fab fa-linkedin icon"></span></a>
      </li>
        
      
    </ul>
  </div>

  <div class="audioplayer-block">
    <div id="audioplayer" class="audioplayer">
      <button id="playpause" class="player-button"><span class="fas fa-play" id="playbutton"></span><span class="fas fa-pause hide" id="pausebutton"></span></button>
      <select id="audiofile" class="player-button tracklist" aria-label="Track to Play">
        <option value="Nine_Inch_Nails-Head_Like_A_Hole.midi.mp3">Nine Inch Nails - Head Like A Hole</option>
        <option value="Prodigy-Breathe.midi.mp3">Prodigy - Breathe</option>
        <option value="Sisters_of_Mercy-Temple_of_Love.midi.mp3">Sisters of Mercy - Temple of Love</option>
        <option value="The_Cult-She_Sells_Sancturary.midi.mp3">The Cult - She Sells Sancturary</option>
        <option value="KMFDM-Megalomaniac.midi.mp3">KMFDM - Megalomaniac</option>
        <option value="Tool-Aenima.midi.mp3">Tool - Aenima</option>
        <option value="Rammstein-Engel.midi.mp3">Rammstein - Engel</option>
        <option value="Rancid-TimeBomb.midi.mp3">Rancid - TimeBomb</option>
        <option value="Mighty_Mighty_Bosstones-The_Impression_That_I_Get.midi.mp3">Mighty Mighty Bosstones - The Impression That I Get</option>
        <option value="Offspring-All_I_Want.midi.mp3">Offspring - All I Want</option>
        <option value="Smashing_Pumpkins-1979.midi.mp3">Smashing Pumpkins - 1979</option>
        <option value="Nirvana-Heart_Shaped_Box.midi.mp3">Nirvana - Heart Shaped Box</option>
      </select>
    </div>
  </div>

  <section class="about-header">
    <div class="navbar-tagline" id="tagline">Move carefully and fix things</div>
  </section>
</nav>
<div class="content" id="main" up-main>
        <section class="posts content-container posts">

  <header class="section-header">
    <h2 class="section-title">posts</h2>
      <ol class="meta-links">
          <li>
            
          </li>
      </ol>
  </header>

  

  <div class="posts-container">
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2022/09/19/social-semantic-web/"up-follow>Social Semantic Web</a></h3>
        </header>
        <div class="post-content">
          
          <p>
            <span class="date">
              2022.09.19
            </span> –
          
            I maintain <a href="/blog/2022/09/03/redesign/">my concern that the web has gotten worse due to closed social media platforms</a>, so I have been thinking a lot lately about decentralized models for social networks - as well as existing open standards that can help to close some of the gaps.

In contrast to the community-building I’m most interested in, here are two ongoing culture wars that are on my mind. One is the battle of content creators - particularly those authors of adult content. These folks keep being squeezed out of popular platforms, while their work is copied &amp; exploited by celebrities. Tumblr used to be the primary home of weird fandoms, but a few years back it removed all adult content in an effort to appease Apple with its PG-13 app store rules. Instagram has become one of the more prominent battlegrounds since then, eliminating accounts with reckless abandon.

A friend was just complaining about having to open their <strong>eighth</strong> account after the previous seven have been systematically removed. These creators are being kicked off even when following the platform’s rules, due to overly-aggressive moderation policies. For these folks, data portability would be a massive improvement, and owning their own websites from which they can share content is increasingly-critical to maintaining a fanbase. Many folks are using <code class="language-plaintext highlighter-rouge">linktr.ee</code> as a sort of mini-homepage to get around some of these limitations - but still not setting up their own personal websites.

The other more sinister war is that of white supremacy + domestic terrorism in America and abroad, where disinformation runs rampant on sites like Facebook and Twitter. Hateful content grows like mushrooms on shit in dark corners such as the *chans, but memes and lies are propagated back to the more mainstream platforms. Decentralization won’t fight the spread of hate in dark corners - and may even exacerbate the growth of the number of corners - but it can potentially fight the recommendation algorithms on mainstream sites showing disinformation to “normal” users.

In approaching these issues, I’ve been thinking about three pieces in particular: <a href="#content-aggregation">Content Aggregation</a>, <a href="#discovery">Discovery</a>, and <a href="#collaboration">Collaboration</a>.

<h2 id="content-aggregation">Content Aggregation</h2>

It’s clear that folks don’t want to visit dozens of separate websites to consume content if they can avoid it, which is how we got where we are today. Content aggregation through feeds via <a href="https://validator.w3.org/feed/docs/rss2.html"><strong>Really Simple Syndication (RSS)</strong></a> (or <a href="https://validator.w3.org/feed/docs/atom.html">ATOM</a>, of course) provides a middle ground: authors can maintain control of their content from their own blogs &amp; domains, but readers can consume content from a variety of sources in a single place.

Google Reader was just about perfect as a feed reader, before Google killed it. It was simple and clean, and it even allowed groups to annotate content together! Over the last year I tried out <a href="https://feedbin.com/">Feedbin</a> and <a href="https://feedly.com/">Feedly</a>, but neither impressed me. Lately I’ve been trying out <a href="https://www.inoreader.com/">Inoreader</a> but I will admit that I find the design overwhelming - it feels like it’s trying too hard to be a social media site. Also the price for a “team” is way too high - which makes it a hurdle for collaboration. If there are other options that you like and I should consider, please drop me a note!

Most modern feed readers (aka RSS readers, though they typically support more than just RSS) use the <a href="http://opml.org/">OPML</a> standard for importing &amp; exporting lists of feeds that you follow. This makes it much easier than before to switch between them - again, adding to the portability.

Several of them also offer fake email inboxes for newsletters. As much as people are switching to Substack and similar platforms, I can’t say I’m a fan of reading email. As a content consumption experience it always feels… <em>invasive</em>, and the formatting is always poor.

<h2 id="discovery">Discovery</h2>

Finding your current friends on various sites continues to be a painful process. Finding new content and folks to follow also tends to be difficult. These days most of the new folks I find as a result of other friends sharing their posts on Twitter. These days, most folks only talk about their own work on their blogs, but including references to other folks’ content greatly aids discovery. I’ve added a “microblog” of recommended content to my website here - again taking a nod from 90s websites - thinking it could help folks find new ideas and creators.

<p id="foaf">I remembered that Livejournal supported the <a href="http://xmlns.com/foaf/0.1/"><strong>Friend-of-a-Friend interchange format (FOAF)</strong></a>, and allowed you to export a list of the folks that you followed in a single XML file. Such a file could easily be automated on modern self-run blogging platforms like Jekyll, Hugo, Wordpress, etc. The same source content could generate a “links” page like we had on websites in the 90s. I’m adding this to my list of things to tinker with on this Jekyll site.

A smart feed reader could even look for a FOAF file and easily help you find your friends’ blogs, as an alternative to OPML. That could then help you find your friends-of-friends, to suggest additional content to you that may be relevant - for instance, blogs that are followed by at least X% of the people you follow, or that follow you.

<h2 id="collaboration">Collaboration</h2>

Collaboration presents a large series of challenges in a decentralized world. For those of us who runs static personal websites, it’s hard to see what content is referencing yours. It’s even harder to receive comments in a public way that’s coherent to your site - replying to a blog post historically requires an account on whatever site you’re on, which doesn’t really work for static sites built with tools like Jekyll.

Wordpress, due to its widespread use and dynamic nature has been rather successful in this area. The <a href="https://wordpress.com/support/comments/pingbacks/">pingback mechanism</a> allows even self-hosted sites to receive a notification if another site mentions them. As I understand it, this works through some sort of central repository of content indexes.

Some folks have implemented the Disqus comment platform on static sites, but they had some serious security issues in the past. That also doesn’t give an easy way to cross-collaborate - the content is still bound to your website, through a centrally-managed provider.

My research on FOAF led me to a number of <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.192.824&amp;rep=rep1&amp;type=pdf">old scholarly articles</a> on the <strong>Social Semantic Web</strong> and specifically the <a href="http://rdfs.org/sioc/spec/">Semantically-Interlinked Online Communities (SIOC) format</a>. This format was a way of defining and linking content across multiple sites, which would also allow portability of content. You could write a post on one site and have it federated to other message boards for replies and interaction.

SIOC seemed to have been a popular idea around 2004-2008, but then appears to have died off completely. It seems to have been another of the interesting/weird/way-too-complicated RDF-based projects that arose during the short period when the open standards community got obsessed with <strong>Linked Data</strong>. My initial impression is that it’s an interesting model, but too difficult for laypeople to use. Sadly, though there were tools built to natively work with SIOC on Wordpress, Drupal, and other popular blogging engines, all have disappeared today - most lost due to linkrot.

Relatedly, I remain skeptical of the <a href="https://www.w3.org/TR/annotation-model/">web annotation movement</a> from the same era (e.g. sites like Genius, née RapGenius) due to my work on that W3 committee. The potential for <a href="https://elladawson.com/2016/03/25/how-news-genius-silences-writers/">abuse and harassment</a> is simply too great and not taken seriously by the community. As such, I’ve largely rejected the concept, but with some healthy and robust standards-based controls (FOAF? robots.txt?) it could potentially have a place in an RSS reader. (Assuming it would default to opt-in not opt-out!)

For the moment, I think the simplest solution might be the easiest. Most web developers are familiar with the <code class="language-plaintext highlighter-rouge">&lt;link&gt;</code> metatag and its <code class="language-plaintext highlighter-rouge">rel</code> attribute, which allows you to define relationships between web pages. Most commonly, we use these for CSS stylesheets, and links to our own RSS feeds on our pages. A less commonly-known attribute is the <a href="https://www.w3.org/TR/relations.html">rev</a>, or reverse, property; basically it’s the opposite of <code class="language-plaintext highlighter-rouge">rel</code>. One could provide a <code class="language-plaintext highlighter-rouge">&lt;link rev="child" href="https://thatsite/over/there/"&gt;</code> in a page’s head, as a declaration that the current page is a reply (a “child”) of the <code class="language-plaintext highlighter-rouge">thatsite</code> page referenced. I’m actually testing that out on the page you’re currently reading!

However, nothing supports this today, so it doesn’t do anything. Again, a clever RSS reader could pull this metadata from an <code class="language-plaintext highlighter-rouge">&lt;entry&gt;</code> and use it to assemble a content tree - or even notify the original author if they provided the proper metadata in their feed. A site owner could also use their own FOAF list or OPML to scrape for entries that are replies from friends and list them on a given page. This makes for an opt-in model which leaves control in the hands of the original creator. I’ll consider this for a later Jekyll plugin project if this concept gains traction.

<h2 id="momentum">Momentum</h2>

Which brings us to the root problem - momentum. FOAF hasn’t gained traction. SIOC died on the vine. All of these more complicated methods didn’t gain mainstream support because they inherently go against the current capitalist model of capturing an audience on one site for increasingly long periods of time. And of course, they’re too complicated for the average person to pick up and use the way they can with just plain old HTML.

That being said, my interest here remains in <strong>digital communities</strong> - and I have some half-baked suspicions that communities have an upper bound on how much they can scale sustainably. So maybe you don’t need enough mass-market appeal for a billion-dollar company, just a simple collection of tools that your community can support.

I’ve started with <a href="https://billhunt.dev/civic-tech-webring/">my little civic tech webring</a> as one example of what can be done at a smaller scale, and I’m starting to think about how a webring could become a “group” (FOAF or otherwise).

As always, if these topics are interesting to you, please <a href="mailto:hello@billhunt.email?subject=Let's%20Talk%20About%20Communities!" class="btn">drop me a line</a>. Or, maybe create a blog post about the topic yourself … and let me know about it!

          
          </p>
          <p>
            <a href="/blog/2022/09/19/social-semantic-web/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2022/09/03/redesign/"up-follow>Making the Web Weirder</a></h3>
        </header>
        <div class="post-content">
          
          <p>
            <span class="date">
              2022.09.03
            </span> –
          
            <h2 id="the-social-media-plague">The Social Media Plague</h2>

Over the last few years, I’ve been struggling with social media.

Growing up in a sleepy college town it was hard to find other weirdos, and the internet provided a new and interesting way to do so. While Usenet, IRC, AOL, MySpace, LiveJournal provided increasingly flexible options to communicate, the thing that brought folks together was a <strong>passion for sharing things they love</strong>. People were intentional in carving out spaces for <strong>communities</strong>, and found new things and ideas they could love. (By the way, <a href="https://www.therealkatiewest.com/">Katie West</a> has put together <a href="https://topatoco.com/products/mtt-birl">a fantastic anthology of stories about finding communities on the internet</a>.)

Advertising has been around from almost the beginning, but social media changed things - instead of advertising showing up alongside the content, the content itself began being driven by the need for advertising. Today, we have sites like Facebook, Instagram, Tiktok, and Twitter actively profiting off of disinformation. Years of user research has enabled these companies to deliver a dopamine hit straight to users for rage-clicking on posts. (If this is sounding like paranoid fantasy, note that <a href="https://theconversation.com/how-cambridge-analyticas-facebook-targeting-model-really-worked-according-to-the-person-who-built-it-94078">there’s plenty of thorough research and documentation on the topic.</a>) Sites are <em>designed</em> to drive folks into these walled gardens, to get them to refresh the page a thousand times a day, every spare minute waiting in line spent staring at phones waiting for the next crumb of content. The COVID-19 pandemic physically isolated most people, and this only amplified the drive to use social media as an escape.

<strong>And it’s making people miserable.</strong> It certainly makes me miserable. And when I’m feeling particularly curmudgeonly, I tend to say that it’s destroying democracy.

<hr />

<h2 id="what-comes-next">What Comes Next</h2>

During the pandemic, following a long period of work-induced burnout, I’ve spent the last year attempting to shift my energy towards productive efforts &amp; creative endeavors. Spending time to share knowledge about my practice &amp; craft. Making weird shit. To steal a phrase from Marie Kondo, I’ve been working on <strong>things that spark joy</strong> - at least in myself, but hopefully in others as well.

One of those efforts was the <a href="/move-carefully/">Move Carefully and Fix Things stickers</a>, though ironically those started from a long (<em>and very divisive</em>) Twitter thread. Another was the <a href="https://digitalpolicy.us/">DigitalPolicy.us</a> website. I put up a Minecraft server to play with friends (<a href="https://twitter.com/krusynth/status/1555246435863494656">come join us!</a>). And most recently, I’ve been making very silly t-shirts designs for government IT policies:

<img src="https://billhunt.dev/uploads/2022/09/FISMA2b-small.png" alt="FISMA image" />

I’ve also been reading more longform writing pieces from smart folks. Not everything <em>needs</em> to be a five-page article, but I’m sure glad that people are putting them out there. But moreover, the <em>discourse</em> emerging from those pieces has been fascinating and insightful.

And so, I had a realization: this is how I want to dedicate my time (outside of work, for now), <strong>finding more productive ways of building communities around things that we love and care about</strong>. At least for a while. The first step was in redesigning this website (more on that in a bit). In the coming weeks and months, I plan to explore what I’m thinking of as <strong>Web 1.1</strong>: modern takes on Blogs, RSS feeds, Webrings, and other basic means of content creation and sharing.

<p class="banner"><strong>Update (the next day):</strong> to be explicit here – I want to embrace unbridled enthusiasm and, as one commenter stated, effervescent joy. I want to <strong>reject cynicism and irony and sarcasm.</strong> I want to try new things and <em>lean into the cringe</em> not away from it. I want people to take pleasure in the act of living and communicating and creating and <strong>being human</strong> without worrying about judgement.
<p class="banner">… that being said we should not tolerate racist, transphobic, sexist, xenophobic assholes in our communities.

These efforts probably won’t fix all that’s wrong with the world today. But at the very least we can make the web a little weirder, a little more decentralized, a little more open and free.

<strong>If you care about these things too,</strong> <a href="mailto:hello@billhunt.email?subject=Let's%20Talk%20About%20Communities!" class="btn">please get in touch!!!</a>

(Do not contact me if you want to talk about Web 3.0 or blockchain, I’m not interested.)

Of course you can always <a href="/civic-tech-webring/" class="btn">join my Civic Tech Webring</a> too - it’s real!!!

<hr />

<h2 id="an-overly-detailed-breakdown-of-my-site-redesign">An Overly-Detailed Breakdown of My Site Redesign</h2>

I had a few things in mind when <a href="https://github.com/krusynth/billhunt.dev/tree/2022">redoing this site</a>. I knew, thematically, that I wanted it to be a throwback to the late 90s era of design, while keeping modern aesthetics. One aspect that was more common back then than today is sharing content off-site, as the inclination nowadays is to get people to your site and keep them there. I wanted to be able to share the neat things I was finding on the web, so I made dedicated space to talk about other folks’ work without needing to overly-editorialize about it. Similarly, I find a lot of great government job postings, and I want folks to know about them because we need more amazing people in government. I used <a href="https://jekyllrb.com/docs/datafiles/">Jekyll’s data files</a> to power these pieces, and <a href="https://github.com/krusynth/billhunt.dev/blob/2022/feed.xml#L17">integrated them into my RSS feed</a>.

I went back to old classic web designs that incorporated mixed content effectively, and started plucking elements I found interesting like blocking and textures. <a href="http://www.cubancouncil.com/work/project/kaliber-10000">K10K</a> was a major source of inspiration, in addition to my own older website designs. I reverted to Silkscreen and Verdana fonts - which I’d used on my site 15 years before - while retaining the more modern Montserrat for headings (which is a decent free clone of the very-expensive Gotham font from HFJ made famous by the Obama Administration).

With CSS <a href="https://css-tricks.com/snippets/css/a-guide-to-flexbox/">flexbox</a> and <a href="https://css-tricks.com/snippets/css/complete-guide-grid/">grid</a> layout methods being supported in most modern browsers, I took a long look at whether I still needed <a href="https://getbootstrap.com/">Bootstrap</a>. Aside from layout blocking, the main thing I was using there was the navigation fallback for mobile browsers &amp; small screens. I’d long since abandoned the multi-tier menus, and condensing down the text gave me more than enough space for a mobile browser. So, out went Bootstrap. For the moment, I’ve kept <a href="https://fontawesome.com/">FontAwesome</a> for icons, though eventually that will probably go as well, to be replaced with SVGs.

Of course, it wouldn’t be a 90s-themed website if I didn’t have a music player, so of course I had to use MIDI files. However, I quickly learned a few depressing facts: 1) modern web browsers do not support MIDI files and 2) no one just keeps webpages of free midis anymore. I had to go digging through the depths of the internet to find a few suitable tracks. I then found the <a href="https://www.npmjs.com/package/web-midi-player"><code class="language-plaintext highlighter-rouge">web-midi-player</code></a> package, itself built on top of <a href="https://www.npmjs.com/package/timidity"><code class="language-plaintext highlighter-rouge">timidity</code></a>. In retrospect, this was a mistake, as I also have to load patch files for every instrument the player will use; in the end, the downloads here are larger than if I’d just used MP3s. Furthermore, the audio driver used is not supported by most mobile browsers, so folks on their phone cannot enjoy my fine musical selections. At some point in the future, I’ll replace these with recorded MP3s of the MIDI files.

Having a MIDI player won’t be very effective if the song stops playing when someone changes pages, so I considered using a pop-out player, but that seemed like it could be less-fun and more-annoying. This seemed like the perfect opportunity to use <a href="https://unpoly.com/">unpoly</a> – a little Javascript addition that turns static websites into single-page apps by loading just particular chunks of pages into the current page. (If you work with Rails, <a href="https://hotwired.dev/">hotwire</a> works similarly.) This way, I can swap out the main content area and leave the rest of the page alone - just like the early days of “DHTML.” One gotcha here is that for unpoly to work with your browser history (the dreaded back button problem), you have to manually set a configuration to tell it where to load it with a line of Javascript after loading, <code class="language-plaintext highlighter-rouge">up.history.config.restoreTargets=[':main'];</code> does the trick here. I’m surprised this isn’t the default.

Finally, I sprinkled in a few easter eggs that only the most dedicated spelunkers would find. Of course, it’s not the web if it’s not weird!

I do need to go back and spend some time cleaning up a few accessibility issues. I’d also like to add a classic-style links page in the future as well, but few folks are keeping their websites active these days. Maybe if this movement grows that will change!

<hr />

At the moment, I’m finishing work on my new t-shirt store, but following that I’ll be spending some time on a little RSS reader I’ve been tinkering with. Hopefully some of you folks will get in touch about collaborating on some of these upcoming projects - I’m looking forward to hearing from you all!

          
          </p>
          <p>
            <a href="/blog/2022/09/03/redesign/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2022/03/15/federal-budget-challenges/"up-follow>Federal Budget Challenges</a></h3>
        </header>
        <div class="post-content">
          
          <p>
            <span class="date">
              2022.03.15
            </span> –
          
            <p class="banner"><em>Just a reminder that this is my personal account and these are my personal thoughts that I’m posting on my personal time. I do not speak for my current or previous government agencies here.</em>

After six months of delay, Congress just passed the annual <a href="https://rules.house.gov/sites/democrats.rules.house.gov/files/BILLS-117HR2471SA-RCP-117-35.pdf">federal appropriations bill for Fiscal Year 2022</a> (which we are halfway through currently). I just saw <a href="https://twitter.com/jmillerWFED">Jason Miller</a>’s article for Federal News Network <a href="https://federalnewsnetwork.com/reporters-notebook-jason-miller/2022/03/in-a-reversal-of-roles-congress-tells-the-tmf-to-show-me-the-money/">pointing out that the Technology Modernization Fund (TMF) had it’s budget completely cut this year</a>.

The <a href="https://tmf.cio.gov/">TMF</a> is a much-needed band-aid on top of a massive problem, providing a source of multi-year funds for agencies that want to improve legacy systems but don’t have the money in their budget. However, alone it won’t be able to stop the bleeding - here’s why.

<h2 id="1-annual-appropriations">1. Annual Appropriations</h2>

One of the main reasons government IT is bad is that it’s chronically underfunded and also not funded <em>in the right way</em>.

Generally money is only appropriated for an agency to use withing a single year. They have to spend it in that time or it goes back to Treasury. This is why agencies buy printers, hardward, etc. at the end of the year, to show they used it all. Obviously, most IT projects can’t be completed in a single year. This means that there is a significant risk to starting a major IT improvement or system overhaul if the money might evaporate next year. (Or if Congress decides to delay on passing the appropriations bill for six months, preventing any additional money from being spent!)

In addition to the TMF, the <a href="https://www.congress.gov/bill/115th-congress/house-bill/2227/text">MGT Act</a> created IT Working Capital Funds for the 24 CFO Act agencies (if they didn’t have one), which cost savings from IT projects can be funneled into, giving them a 3-year window to use saved money. This is capped at only a couple million dollars for each agency, usually about 3% of total salaries and expenses.

(If I recall correctly, only the Department of Labor can sweep unused funding at the end of the year into their IT Working Capital Fund though. Also, of course, non-CFO Act agencies - all of the “smalls” - don’t usually have an IT WCF at all!)

Needless to say, this makes major improvements almost impossible. <a href="https://www.gao.gov/products/gao-21-524t">GAO has a series of reports on the needed improvements</a> - but it barely scratches the surface of the problem, highlighting only 10 systems out of <strong>THOUSANDS</strong>. And it doesn’t even cover the most important ones!

<h2 id="2-competing-spending-priorities">2. Competing Spending Priorities</h2>

The three big categories of spending in a government agency typically are: A. Rent; B. Salaries; C. Technology. After the first two get paid, IT finally gets a cut at what’s left. Note that the current “return to work” is a push to fill empty offices to justify constantly-increasing Rent. Salaries haven’t kept up with inflation, but still aren’t going down. That leaves only IT to keep taking a cut because some people want full offices to justify renting the space, instead of downsizing and maximizing remote/telework. (VA &amp; GSA are big exceptions, which have embraced remote and closed offices!)

<a href="https://billhunt.dev/uploads/2022/03/tobefair.jpg">To be fair</a>, there have been some efforts to get IT higher up the priority list for agencies, notably <a href="https://www.congress.gov/bill/113th-congress/house-bill/1232/text">FITARA</a>. However, FITARA doesn’t force agencies to actually modernize, and moreover FITARA only applies to the CFO Act agencies (notice a pattern yet?).

The Budget side of The Office of Management and Budget (OMB) is somewhat isolated from the Management side (&amp; IT policy), so priorities don’t always translate. E.g., the main methodology for tracking IT spending &amp; investment is the <a href="https://www.whitehouse.gov/wp-content/uploads/2020/11/FY22ITBudget_CapitalPlanningGuidance.pdf">IT Capital Planning and Investment Control (CPIC)</a> process, which is mostly not connected to the Federal Budget process.

Of course, priorities even within the Management side aren’t necessarily coordinated. Although CPIC has risk and performance management elements, it mostly isn’t attached to any of the other ongoing priorities; just look at the latest Executive Orders on <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2021/05/12/executive-order-on-improving-the-nations-cybersecurity/">Cybersecurity</a> or <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2021/12/13/executive-order-on-transforming-federal-customer-experience-and-service-delivery-to-rebuild-trust-in-government/">Customer Experience</a> - no mention of CPIC, and little-to-no funding for these mandates. Even though it seems obvious that work to improve security or satisfaction with services should be tied to funding measures, there are instead lots of silos and political territories sliced up.

<h2 id="3-disconnected-processes">3. Disconnected Processes</h2>

The budget process itself is a weird game of chicken between various elected, political, and career officials. CIOs &amp; CFOs know the tech debt gap, Department Secretaries/Administrators know the costs, but may not feel comfortable putting forth an accurate budget request. And when an Administration decides it wants to make reductions for, say, political reasons, IT generally is the first place to get cut.

Then of course, Congress passes whatever budget it wants, ignoring what the President asks for. <a href="https://progress.institute/preventing-pandemics-requires-funding/">(Here’s a non-IT example that’s incredibly frustrating.)</a> There are some really solid members that know their stuff, but most of them are clueless on tech. So when it comes to appropriations, it’s a bit like asking your grandma for that hot new Nintendo game and she buys you this:

<img src="https://billhunt.dev/uploads/2022/03/electronic-soccer.jpg" alt="Tiger Handheld Electronic Soccer Game from the 80s" />

(And I’m not going to get into the toxic “outsource everything tech” lobotomization of government staff issue in this rant. <a href="/blog/2020/12/19/federal-policy-recs/">That’s for another day.</a>)

<h2 id="in-conclusion">In Conclusion</h2>

This is all to say that it’s a big house of cards built on a series of broken processes. Although IT spending has increased steadily year after year, it’s still not enough to keep up with even basic upkeep of key systems. I expect we’ll see more and more high-profile failures and exploits in the near future as a result of these gaps.

I do want to say that there are lots of good folks working to make incremental progress, but we won’t see any major revolutions in how services are provided by the government until Congress &amp; the President agree to truly stop the bleeding.

          
          </p>
          <p>
            <a href="/blog/2022/03/15/federal-budget-challenges/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2021/03/07/cloud-strategy-guide/"up-follow>Cloud Strategy Guide</a></h3>
        </header>
        <div class="post-content">
          
            <p>
              <img src="/uploads/2021/02/cloud-strategy-guide.png" class="featured-image">
            </p>
          
          <p>
            <span class="date">
              2021.03.07
            </span> –
          
            <div class="wrapper-outer">
<div class="wrapper-inner">
   <div class="wrapper-subtitle">
    <span class="fas fa-bars outlined"></span>
    <span class="subtitle-first outlined">Cloud</span>
    <span class="fas fa-bars outlined"></span>
  </div>
  <span class="subtitle-wrapper-text top-text">Strategy</span>
  <span class="subtitle-wrapper-text bottom-text">Guide</span>
</div>
</div>

In <strong><a href="/blog/2021/02/28/cloudbusting/">part one</a></strong>, I discussed many of the myths around cloud use in government. In this article, I will describe critical strategies to address these myths that every organization should embrace before, during, and after moving to the cloud. These strategies are generally intended for civilian Federal agencies of the United States, but the recommendations below apply to any public sector organization - and even some private organizations as well.

<em>Both guides are available to download as <a href="/uploads/2021/03/CloudGuide.pdf">a single PDF <span class="fas fa-cloud-download-alt fa-lg"></span> </a></em>

<ol class="table-of-contents">
  <li><a href="#chapter-1---migrate-pragmatically">Chapter 1 - Migrate Pragmatically</a></li>
  <li><a href="#chapter-2---plan-to-your-budget--staff">Chapter 2 - Plan to Your Budget &amp; Staff</a></li>
  <li><a href="#chapter-3---embrace-new-security-models">Chapter 3 - Embrace New Security Models</a></li>
  <li><a href="#chapter-4---understand-what-youre-buying">Chapter 4 - Understand What You’re Buying</a></li>
  <li><a href="#chapter-5---build-a-family-farm">Chapter 5 - Build a Family Farm</a></li>
  <li><a href="#epilogue---getting-more-help">Epilogue - Getting More Help</a></li>
</ol>

<h2 id="chapter-1---migrate-pragmatically">Chapter 1 - Migrate Pragmatically</h2>

The first thing to accept is that not all projects are appropriate for the cloud, and not all organizations have the skills necessary to fully take advantage of the cloud. With that as a starting point, an organization needs to come up with a way to rationalize its application portfolio, to determine what should stay on-premises and what should be modernized.  As a general rule, “lift-and-shift” - moving an application without rewriting it for the cloud environment - is <em>almost never cost-effective</em> for Infrastructure as a Service (IaaS) offerings unless it’s already a <em>very</em> modern system in the first place. On the other hand, basic websites with mostly static content are ideal for moving into Software as a Service (SaaS) or Platform as a Service (PaaS) offerings.

The CIO Council’s <a href="https://www.cio.gov/assets/files/Application-Rationalization-Playbook.pdf">Application Rationalization Playbook</a> (disclaimer: another document I worked on) is a useful starting point for this evaluation. Specifically, an agency should work up a thorough analysis of alternatives between various SaaS, PaaS, and IaaS offerings against the existing on-prem setup, or a hybrid environment. A major consideration here will be the Total Cost of Ownership (TCO), which should take into account not just service costs, but also staffing, support, and training costs. However, the lowest priced option may not always be the best choice (as I’ll be covering below).

<a href="https://cloud.gov/">Cloud.gov</a>, is an offering from the General Services Administration (GSA) that bundles several Amazon Web Services (AWS) offerings in a government-friendly “procurement wrapper” can make migration even easier for agencies. It’s an excellent platform for small agencies, or for large agencies that just want to prototype a new concept quickly.

When you do start moving applications, it’s important to start tagging your assets - accounts, virtual machines, workflows, etc. - as early as possible to make accounting easier. Always include the project name and the customer organization at a minimum. Some providers also allow you to easily isolate a project or office’s services into a resource group, and this can also simplify this process. This is very important to allow easy payback or showback of funds, but for these models remember to include in these costs the TCO aspects not captured - e.g. staff time and contractor resources.

I strongly recommend agencies take a very <em>cynical</em> stance on so-called low-code/no-code platforms, customer-relationship management tools (CRMs), and workflow management solutions. Many of you may remember the promises of “Business Intelligence” solutions in decades past, where agencies were fleeced for billions of dollars in configuration costs - these solutions are simply using a new buzzword for the same idea. These all promise to reduce costs but are often vastly more expensive than just building a tool from scratch - and the agency becomes <em>completely</em> locked-in to a single vendor until they replace the application entirely. The brilliant <a href="https://twitter.com/sboots">Sean Boots</a> of the Canadian Digital Service has presented a <a href="https://sboots.ca/2020/09/16/fake-cots-and-the-one-day-rule/">“1-day rule” to help identify these boondoggles</a>.

<table class="checklist">
  <thead>
    <tr>
      <th> </th>
      <th>Checklist</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><span class="far fa-balance-scale-right"></span></td>
      <td>Rationalize the application portfolio</td>
    </tr>
    <tr>
      <td><span class="fa-stack"><span class="far fa-truck fa-stack-1x"></span><span class="far fa-ban fa-stack-2x"></span></span></td>
      <td>Don’t lift-and-shift</td>
    </tr>
    <tr>
      <td><span class="fa-stack"><span class="fas fa-university fa-stack-1x"></span><span class="fal fa-cloud fa-stack-2x"></span></span></td>
      <td>Use cloud.gov</td>
    </tr>
    <tr>
      <td><span class="far fa-tag"></span></td>
      <td>Properly tag cloud assets</td>
    </tr>
    <tr>
      <td><span class="fa-stack"><span class="fas fa-snake fa-stack-1x"></span><span class="far fa-ban fa-stack-2x"></span></span></td>
      <td>Avoid low-code/no-code/crm snake oil</td>
    </tr>
  </tbody>
</table>

<h2 id="chapter-2---plan-to-your-budget--staff">Chapter 2 - Plan to Your Budget &amp; Staff</h2>

The easiest way to avoid risks and unexpected costs is to simplify as much as possible. Civilian agencies should not be investing in bleeding-edge technology solutions - they’re too risky and expensive to maintain. Instead, pick the simplest possible solution that can be supported by your staff. The average agency should be aiming to stay well behind the <a href="https://en.wikipedia.org/wiki/Hype_cycle">“hype curve” into the “plateau of productivity.”</a> 
Since most of the complexity is hidden from the customer, SaaS and commercial-off-the-shelf (COTS) tools are less risky than PaaS and IaaS options overall (provided you follow the 1-day rule above). This goes beyond just cloud, and applies to most anything you’re <em>building</em>. Most agencies, for instance, also should absolutely not be attempting to build a fancy React/Redux/GraphQL single-page application when a plain Wordpress or Drupal website with a few plugins will fulfill the customer’s needs. Building native mobile applications should be <em>completely avoided</em> by most organizations as these can cost millions of dollars a year just for upkeep - instead they should build mobile-friendly, responsive websites. Any custom application or tool may not be a sustainable solution given the high complexity and cost of engineers. This also means that agencies should be simplifying their <em>requirements</em> to the minimum necessary when comparing alternatives, not just the software itself. Avoiding “one-off” projects and special requests will save massive amounts of time and money.

Instead, agencies must be actively investing in <em>their staff</em>. Agencies should allocate two to three times the standard training budget for IT and technology-adjacent staff, including project managers, program managers, and acquisition professionals. Some vendors provide a limited amount complementary training, but inevitably agencies need more than these free offerings. This training should include non-IT topics as well, including diversity awareness training, accessibility, plain language writing, project management, agile development techniques, and budgeting and procurement. <a href="https://www.gsa.gov/about-us/events-and-training/gsa-training-programs/training-opportunities-for-federal-employees">GSA offers a variety of programs</a> covering many of these areas.

This must also include hands-on training - sitting through a webinar is no replacement for actual practical engineering experience. These staff need to be given the time and flexibility to practice these skills to develop them - building small test projects and trying out tools. The best teams are constantly changing and learning, so setting aside up to 10% or more of the staff’s time just for practice is not unreasonable - some <a href="https://en.wikipedia.org/wiki/20%25_Project">private sector companies set aside 20%</a>. All of these investments will pay off richly for agencies. Also, make sure your staff is cross-trained and able to fill gaps as they occur.

As your staff begins to understand the new cloud paradigms, it will be important to modify your existing processes to handle the agility the cloud brings. Instead of slow, end-to-end, waterfall process “monorails”, set operational parameters as “guiderails.” Your acquisition process should be modified so that cloud can be purchased like a utility. You should not need to have a Change Control Board meeting anytime someone wants to create, resize, or destroy a virtual server. Plan a cost range that the entire project will fit within and review as needs change, along with monthly or quarterly portfolio reviews to stay on top of the budget. Instead of codified “gold disk” server images maintained by your team, consider template security rules.

<table class="checklist">
  <thead>
    <tr>
      <th> </th>
      <th>Checklist</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><span class="far fa-bicycle"></span></td>
      <td>Simplify the requirements and architecture</td>
    </tr>
    <tr>
      <td><span class="fa-stack"><span class="far fa-mobile-alt fa-stack-1x"></span><span class="far fa-ban fa-stack-2x"></span></span></td>
      <td>No mobile apps, avoid single-page webapps</td>
    </tr>
    <tr>
      <td><span class="far fa-user-graduate"></span></td>
      <td>Train and cross-train your staff</td>
    </tr>
    <tr>
      <td><span class="far fa-chess-clock"></span></td>
      <td>Allocate time for personal development</td>
    </tr>
    <tr>
      <td><span class="fas fa-subway"></span></td>
      <td>Update processes to set guardrails instead of monorails</td>
    </tr>
  </tbody>
</table>

<h2 id="chapter-3---embrace-new-security-models">Chapter 3 - Embrace New Security Models</h2>

Agencies must be able to manage the security of everything they run. Going back to the previous strategy, an agency should not deploy anything it cannot manage, and that goes for security as well. This is equally true in on-premises environments, but new operating models require new security models. Both your operations and security teams will need to be familiar with just about every setting that can be changed in your cloud environment - and how to lock them down to prevent exploitation.

Organizations should no longer assume that a solution is secure just because they did an up-front initial review. The Federal government uses a security review process for services and applications known as the Authorization (or Authority) To Operate (ATO), but the implementation varies from agency to agency. Traditionally this is a series of <a href="https://nvd.nist.gov/800-53">standard security controls</a> that are reviewed, checklist-style, by an agency once every three years. However, agencies that have excelled at cloud security have moved to Continuous Authorization, using monitoring tools to actively verify that the security controls are being met and maintained, twenty-four hours a day and seven days a week.

However, these monitoring checks still must evolve with the products being monitored to make sure new vulnerabilities have not appeared outside the scope of existing checks. As per usual with cybersecurity, vigilance is key. Since attackers are constantly evolving their methods, tools that <em>automate security responses</em> as well should be used whenever practical - especially built-in, native from the large vendors that are constantly evolving to meet these threats.

To help combat this second issue, the Federal government has been moving away from so-called “castle-and-moat” perimeter-based security methods which only monitor network traffic. Instead, an approach known as Zero Trust has appeared, taking a data-first methodology of protecting systems instead of <em>just</em> the perimeter, verifying user identities in real-time, and allowing staff to only have access to the minimum amount of information necessary to fulfill the task at hand. In this way, when the perimeter is <em>inevitably</em> breached, the data assets contained within are still secure.

It also should go without saying that teams should be using multi-factor authentication on all privileged accounts. Whether developers or administrators, using more than just a username and password will dramatically reduce the risk of exploitation. The Federal government has “<a href="https://www.fedidcard.gov/">PIV cards</a>” that are generally used on most devices, but if the vendor does not support them, implementing a token system via any of the commercially-available platforms is fine: Google Authenticator, 1Password, Microsoft Authenticator, and YubiKey are all worth looking at. However, organizations should completely avoid text-message codes sent to phones, as these are easily intercepted.

For public customers that will need to login or prove their identies, <a href="/blog/2021/02/18/login-gov-for-everyone/">all U.S. government agencies should be using Login.gov</a>.

<table class="checklist">
  <thead>
    <tr>
      <th> </th>
      <th>Checklist</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><span class="far fa-toggle-on"></span></td>
      <td>Research all product configuration settings</td>
    </tr>
    <tr>
      <td><span class="far fa-binoculars"></span></td>
      <td>Implement continuous monitoring, not just compliance</td>
    </tr>
    <tr>
      <td><span class="fas fa-cogs"></span></td>
      <td>Use security automation tools</td>
    </tr>
    <tr>
      <td><span class="far fa-fingerprint"></span></td>
      <td>Leverage zero-trust practices to protect your data</td>
    </tr>
    <tr>
      <td><span class="far fa-id-badge"></span></td>
      <td>Use MFA &amp; Login.gov</td>
    </tr>
  </tbody>
</table>

<h2 id="chapter-4---understand-what-youre-buying">Chapter 4 - Understand What You’re Buying</h2>

Cloud isn’t going to make your teeth whiter or your breath fresher or fix all of your problems, regardless of what the salespeople tell you. You need to know <em>exactly</em> what you’re buying. Before making an investment, make sure you fully understand what capabilities you’re purchasing and what parts you - and the vendor - will be responsible for.

If your evaluation team does not have technical expertise, bring engineers into the conversation early, to sort the truth from the sales pitch. As discussed in the previous article, you may not be getting autoscaling or load balancing or other features you’ve assumed just happen “automatically” - and if available these features definitely will not be free. You may have to build more “glue” between services than you assume, and someone will have to maintain this connective tissue.

Also keep in mind that the government cloud regions (or “govcloud” by some vendors’ naming) provide different versions of these tools than the commercial ones. As a result, not all features or solutions will be available - so again, plan ahead. Though, in most cases, civilian agencies not dealing with highly-sensitive data should consider using the commercial versions whenever possible - the security differences are not so great as to be insurmountable, but the functionality limitations are huge.

Before implementing a service, do careful research on the service limits - maximum traffic or number of virtual machines or emails that can be sent, etc.. Do <em>not</em> just trust what you are told by a vendor’s engineers or customer representatives - most of the time, they also do not know about these limits until you run aground on them. You should estimate your expected usage - number of site visits and/or users and/or emails, etc., and actually spend the time to search through user forums to make sure no one has hit a limit related to what you’re doing.

Customer Experience (CX) is another area where the private sector has been building people-friendly interfaces into their SaaS solutions, and agencies can skip a lot of the hard work and directly benefit from the results. Metrics and feedback-loops are often built-in as well. Maximizing these built-in elements can radically improve an agency’s public satisfaction scores at little or no additional cost.

<table class="checklist">
  <thead>
    <tr>
      <th> </th>
      <th>Checklist</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><span class="nowrap far"><span class="fas fa-chess-queen-alt"></span><span class="far fa-chess-pawn-alt"></span></span></td>
      <td>Validate assumptions; know your responsibilities</td>
    </tr>
    <tr>
      <td><span class="far fa-door-open"></span></td>
      <td>Consider commercial cloud instead of govcloud</td>
    </tr>
    <tr>
      <td><span class="far fa-unicorn"></span></td>
      <td>Research service limits in advance</td>
    </tr>
    <tr>
      <td><span class="far fa-comment-alt-smile"></span></td>
      <td>Leverage built-in CX tools</td>
    </tr>
  </tbody>
</table>

<h2 id="chapter-5---build-a-family-farm">Chapter 5 - Build a Family Farm</h2>

Given that agency IT budgets continue to be cut, and <a href="https://www.whitehouse.gov/wp-content/uploads/2020/02/hist16z1_fy21.xlsx">staffing has not increased in 40 years</a>, agencies are largely unprepared to completely rewrite and replace all of their legacy systems.  Moreover, “IT Modernization” as a concept is an unending pursuit, as in <a href="https://en.wikipedia.org/wiki/Zeno%2527s_paradoxes%23Achilles_and_the_tortoise">Zeno’s paradox of Achilles chasing the Tortoise,</a> software written today is legacy tomorrow. Agencies will need to use <a href="https://www.congress.gov/bill/115th-congress/house-bill/2227/text">all available funding sources</a> to overcome their deep technical debt, prioritizing those that present the <em>greatest risk</em>: those that are unmaintained, frequently used by customers, and lacking in resilience and redundancy. Under this scrutiny, agencies may find that their public websites are a bigger risk than older backend systems.

Also, rather than replacing entire large monolithic systems, they should <a href="https://www.appdynamics.com/blog/product/strangler-pattern-migrate-to-microservices-from-a-monolithic-app/">pull off pieces and replace them independently</a> as resources are available.  This can be done by isolating functions and building <a href="https://en.wikipedia.org/wiki/Microservices">microservices</a>, but that approach can often lead to expensive, unnecessary complexity. Agencies should not be afraid to build a newer parallel monolith adjacent to the existing one - again, keep in mind that it’s not the size that’s the concern, but the complexity and sustainability.

That all being said, the government does have major shortcomings in redundancy today, and too many systems have a single point of failure. At a minimum, agencies should be using cloud for data backup of critical systems whenever possible. I also strongly recommend agencies consider creating load balancing and caching layers in the cloud in front of on-premise public-facing systems to deal with unexpected loads.

One final concern is automation. Many organizations begin their cloud journey with unrealistic goals for maturity. The practice of Infrastructure as Code is incredibly popular at the moment, where we talk about treating virtual servers as “cattle, not pets.” An unprepared agency may immediately think that they need to be using all of the most cutting edge <a href="https://www.docker.com/">tools</a> and <a href="https://kubernetes.io/">technologies</a> at first, but this would be a critical mistake. Instead, following the principles relating to complexity in the sections above, agencies should aim to create a “family farm” - <a href="https://www.youtube.com/watch?v=_ICzo5r-7vY">only automating that which they can realistically manage</a>. For instance, there is absolutely nothing wrong with only using a few virtual machines and load balancers instead of a fully configuration-only architecture. The great thing about cloud is you can evolve as your team grows, but it’s incredibly difficult to reduce complexity you’ve invested in if your team shrinks.

<table class="checklist">
  <thead>
    <tr>
      <th> </th>
      <th>Checklist</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><span class="far fa-exclamation-triangle"></span></td>
      <td>Assess technical debt by risk</td>
    </tr>
    <tr>
      <td><span class="far fa-crop-alt"></span></td>
      <td>Replace monoliths a piece at a time</td>
    </tr>
    <tr>
      <td><span class="fa-stack"><span class="fas fa-robot fa-stack-1x"></span><span class="far fa-ban fa-stack-2x"></span></span></td>
      <td>Don’t over-automate</td>
    </tr>
    <tr>
      <td><span class="far fa-copy"></span></td>
      <td>Use cloud backups and load balancing as soon as possible</td>
    </tr>
    <tr>
      <td><span class="fas fa-tractor"></span></td>
      <td>Build a small “family farm” to start</td>
    </tr>
  </tbody>
</table>

<h2 id="epilogue---getting-more-help">Epilogue - Getting More Help</h2>

These strategies are a starting point towards a successful cloud rollout. If you run into trouble, want to talk shop with your peers, or would like to share your own strategies and experiences, there are several communities to engage with:

<ul>
  <li>
    The Federal CIO Council <a href="https://digital.gov/communities/cloud-infrastructure/">Cloud and Infrastructure Community of Practice</a> is the main Federal group for discussing these topics. However, they are currently in the process of changing their charter to allow any U.S. government staff to participate: Federal, state, and local. Membership is free.
  </li>
  <li>
    The ATARC <a href="https://atarc.org/working-groups/cloud-working-group/">Cloud and Infrastructure Working Group</a> is free and open to any government staff, though private sector companies must pay to be members.
  </li>
  <li>
    <a href="https://atarc.org/event/cloud-coffee/">Cloud &amp; Coffee</a> (presented by ATARC &amp; MorphWorks) is a biweekly podcast hosted by myself and <a href="https://www.linkedin.com/in/chris-oglesby-94234112/">Chris Oglesby</a>. Each episode, we chat with a guest about their personal experience with technology modernization, and there’s a live Q&amp;A open during the chat. Any ATARC member can participate; old episodes are <a href="https://open.spotify.com/show/6AU2VxO4j7dtDls4ouxdIq?si=YwhQcD7XRGWvxSQJKRmmbw">publicly available on Spotify</a>.
  </li>
</ul>

<span class="fas fa-broom secret-button" title="ITS A SECRET TO EVERYBODY"></span>

<div class="secret-wrapper" style="display:none"></div>

<script>
$(document).ready(function() {

/* Strategy Guide secret */
$('.fa-broom.secret-button').click(function() {
  $('.secret-wrapper').show();
});

$('.secret-wrapper').click(function() {
  $('.secret-wrapper').hide();
});

});
</script>


          
          </p>
          <p>
            <a href="/blog/2021/03/07/cloud-strategy-guide/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2021/02/28/cloudbusting/"up-follow>Cloudbusting</a></h3>
        </header>
        <div class="post-content">
          
            <p>
              <img src="/uploads/2021/02/cloudbusting.png" class="featured-image">
            </p>
          
          <p>
            <span class="date">
              2021.02.28
            </span> –
          
            <img src="https://billhunt.dev/uploads/2021/02/cloudbusting.png" alt="Title: Cloudbusting. Retro 80s video game (pixel art) style portrait of Kate Bush in front of a car" class="feature-image" />

<strong>Get in loser, we’re going cloudbusting! Image by Bill Hunt.</strong>

<em>The “Cloudbuster” was a device invented by William Reich to create clouds and rain by shooting “energy” into the sky through a series of metal rods. Although Reich was paid by many desperate farmers to produce rain, the device was never proven to work.</em>

It’s been ten years since the Office of Management and Budget (OMB) released the original <a href="https://obamawhitehouse.archives.gov/sites/default/files/omb/assets/egov_docs/federal-cloud-computing-strategy.pdf">Federal Cloud Computing Strategy</a>. I had the opportunity to update this strategy two years ago when I served as the Cloud Policy Lead at OMB. Having spent 20 years in the private sector building bleeding-edge cloud infrastructure for some of the best known companies in the world, I was able to leverage my practical experience in the creation of the <a href="https://cloud.cio.gov/strategy/">2019 Federal Cloud Computing Strategy, “Cloud Smart”</a>.

During the course of my work at OMB, I spoke with hundreds of practitioners, policy experts, and Chief Information Officers (CIOs) across government. From this vantage point, I had an intimate view into the entire Federal technology portfolio and learned that many myths about cloud computing were being accepted as truth.

In this article, I’ll debunk key myths about cloud adoption, and explain why - and when - cloud is appropriate for government. These myths are generally intended for civilian Federal agencies of the United States, but the recommendations below apply to any public sector organization - and even some private organizations as well. In <a href="/blog/2021/03/07/cloud-strategy-guide/"><strong>part two</strong></a>, I’ll discuss some strategies for overcoming the pitfalls discussed here.

<em>Both guides are available to download as <a href="/uploads/2021/03/CloudGuide.pdf">a single PDF <span class="fas fa-cloud-download-alt fa-lg"></span> </a></em>

<hr />

<h2 id="myth-1-cloud-is-cheaper">Myth 1: Cloud Is Cheaper</h2>

The main reason cited by Federal agencies to move to commercial cloud is the promise of cost savings. This myth originated with vendors and was <a href="https://www.congress.gov/bill/113th-congress/house-bill/1232/text">repeated by Congress</a>, eventually becoming a common talking point for Executive Branch agencies. Unfortunately, it is based on false premises and poor cost analyses. In practice, the government almost <em>never</em> saves actual money moving to the cloud - though the capabilities they gain from that investment will usually result in a greater <em>value</em>.

At a glance, it can appear that moving applications to the cloud may be cheaper than leaving them in a data center. But in most cases, a Federal agency will not see much, if any, cost savings from moving to the cloud. More often than not, they end up spending many times more on cloud than for comparable workloads run in their data center. Experts have <a href="https://bits.blogs.nytimes.com/2009/04/15/when-cloud-computing-doesnt-make-sense/">known this was a myth for at least a decade</a>, but the lobbyists and salespeople were simply louder than those who had done the math.

First, it’s important to note that most Federal agencies own outright the facilities their data centers are located in. In the 1980s and 1990s, agencies began repurposing existing office space for use as data centers, adding in advanced cooling and electrical systems to support their growing compute needs. This changes the equation for the total cost of ownership because the facilities are already built and can be run <em>relatively</em> cheaply, though they may be partially or fully staffed by contractors due to the <a href="https://billhunt.dev/blog/2020/12/19/federal-policy-recs/">constant push to outsource all work</a>. The government has also built a <em>few</em> best-in-breed data centers such as the <a href="https://www.datacenterknowledge.com/archives/2014/09/30/new-social-security-data-center-comes-online-in-maryland">Social Security Administration’s flagship data center</a> that can compete with some of the most efficient commercial facilities in the world, with solar collectors for electricity generation, and advanced heat management systems for reduced energy usage. However, these super-efficient facilities are only represent a handful of the <a href="https://itdashboard.gov/drupal/data-center-statistics">over 1500 data centers the government owns and operates</a>, and cost half a billion dollars each to build.

Second, agencies routinely run their servers and equipment well past the end-of-life to save money. There are no Federal requirements to update hardware. In fact, until recently, <a href="https://obamawhitehouse.archives.gov/sites/default/files/omb/memoranda/2016/m_16_19_1.pdf">Federal data center requirements for efficiency</a> measured the utilization of servers by time spent processing, which <em>disincentivized</em> agencies from upgrading - older hardware runs slower and thus results in a higher <em>utilization</em> rate for a given task than a newer, more efficient server that completes the task quickly. During a budget shortfall, an agency with a data center has the option of skipping a hardware refresh cycle or cutting staff to make up the deficit; meanwhile, an agency that is all-in on cloud loses this option, as they will have to continue paying for licenses, operations and maintenance costs. As a result, agencies will need to future-proof their plans in more innovative ways, or better communicate funding priorities to OMB and Congress.

Also, it’s important to realize that once the government does buy hardware, the government owns it outright. When you move your application to a commercial cloud, you’re paying a premium for data storage even if it’s just sitting around and not being actively used - for large amounts of data, cloud costs will quickly skyrocket. The government maintains <em>decades</em> worth of massive data sets - NASA generates <em>terabytes</em> of data per day, and even a tiny agency like the Small Business Administration has to maintain <em>billions</em> of scanned loan documents going back to its inception sixty years ago. This is why some <a href="https://www.geekwire.com/2018/dropbox-saved-almost-75-million-two-years-building-tech-infrastructure/">major companies have moved away from commercial cloud and built their own infrastructure instead</a>.

I would note that the idea of workload portability  - moving a service between different cloud vendors, generally to get a cheaper cost - is also largely a myth. The cost to move between services is simply too great, and the time spent in building this flexibility will not realize any savings. Moreover, every cloud vendor’s offering is just <em>slightly</em> different from its peers, and if you’re only using the most basic offerings which are  identical - virtual servers and storage - you’re missing out on the full value that cloud offers.

<h2 id="myth-2-cloud-requires-fewer-staff">Myth 2: Cloud Requires Fewer Staff</h2>

Another promise of cloud cost savings is that an agency no longer has to keep data center engineers on staff. These practitioners are usually comparatively cheap to employ in government, and rarely reach a grade above GS-13 ($76K-$99K annual salary) and agencies moving to cloud will instead employ comparatively expensive DevSecOps practitioners, site reliability engineers, and cloud-software engineers to replace them when moving applications to IaaS or PaaS. These types of staff are extremely difficult to hire into government as they make very high salaries in the private sector, well in excess of the highest end of the General Schedule pay scale (GS-15: $104K-138K), even assuming an agency has the budget and staff slots open to create a GS-15 position in the first place. Due to the <a href="https://billhunt.dev/blog/2020/12/19/federal-policy-recs/">many flaws in the government hiring process</a>, it also can be very difficult to recruit these people into government, even with the new <a href="https://www.opm.gov/news/releases/2019/04/opm-releases-new-direct-hire-process-for-it-positions/">OPM hiring authorities</a> to streamline this process.

An agency that chooses to outsource these skills will often find that contractors may cost even more than hiring capable staff. The agency will still need to have staff with cloud experience to actively manage these staff, and contracts will need to be carefully crafted around concrete outcomes so that the agency is not fleeced by a vendor.

Another overlooked cost here is training. New solutions aren’t always easy for agencies to adopt - whether that’s a fancy software development tool or something as simple as a video chat platform. Personally, a day doesn’t go by that I don’t find myself explaining to a customer some aspect of Teams or Sharepoint they don’t know how to use. Agencies often must provide formal training, and of course there’s inevitably a loss of productivity while teams get up to speed on the new tools and solutions. Since many SaaS vendors roll out new features extremely rapidly, this can present a challenge for slow-to-adapt agencies. Although some training is provided free from vendors, this rarely suffices for all of an agency’s needs, so in most cases further training will have to be purchased.

<h2 id="myth-3-cloud-is-more-secure">Myth 3: Cloud Is More Secure</h2>

A constant refrain is that cloud is safer and more secure, owing to the fact that the servers are patched automatically - meaning that key security updates are installed immediately, rather than waiting for a human to make the time to roll out all of these updates.  For a large enterprise, this is historically a very time-consuming manual process, which automation has improved dramatically. However, the same tools that major corporations use for patching in the Cloud are largely open source and free, and they can be used in an agency’s own data center.

Moreover, it’s important to note that cloud does not remove complexity, it only hides it in places that are harder to see.  When it comes to security, this is especially true, as organizations must adapt to highly-specialized security settings that are not always easily found, particularly with the IaaS offerings. These settings are also constantly changing because of the constant-patching of these vendors, and all too often with little notice in the case of SaaS offerings. This “double-edged sword” has resulted in a number of <a href="https://medium.com/swlh/capital-one-data-breach-a-cloud-security-case-study-7a06e00460">high-profile cloud-related breaches</a> over the last few years - affecting both the public and private sectors alike as we learn best security practices the hard way.

Cloud vendors have also been… less than enthusiastic about meeting government security and policy requirements, unless the government is willing to pay a very high premium for the privilege of security. (I talked about this contentious relationship more in my post on <a href="https://billhunt.dev/blog/2020/12/21/ai-ml-rpa-principles/">Automation Principles</a>.) For instance, as of today no major cloud vendor completely meets the <a href="https://www.whitehouse.gov/wp-content/uploads/2020/11/M-21-07.pdf">government requirements for IPv6</a> which have been around for 15 years and which OMB recently revised to try to get them to move faster.

<h2 id="myth-4-cloud-is-more-reliable">Myth 4: Cloud Is More Reliable</h2>

This one is less of a myth and more of an overpromise, or fundamental misunderstanding of the underlying technology. For a long time, one of the main pitches of cloud is that of self-healing infrastructure - when one server or drive fails, a new one is spun up to replace it. Although this is something that <em>can</em> be implemented in the cloud, it’s definitely not the default. Specifically, for IaaS solutions, you have to build that into your application - and you don’t get it for free.

Relatedly, many agencies assume that any application put into the cloud will automatically scale to meet any demand. If your agency’s website gets mentioned by the President, let’s say, you wouldn’t want it to collapse due to its newfound popularity. Without building infrastructure designed to handle this, simply being “in the cloud” will not solve this problem. However, solving it in the cloud will likely be faster than waiting for physical servers to be purchased, built, shipped, and installed - assuming you have staff on-hand who can handle the tasks.

It is important to keep in mind cloud is, by definition, <em>ephemeral</em>. Servers and drives are often replaced with little-to-no notice. I’ve frequently had virtual machines simply become completely unresponsive, requiring them to be rebooted or rebuilt entirely. When you’re building in the cloud, you should assume that anything could break without warning, and you should have recovery procedures in place to handle the situation. Tools like <a href="https://netflix.github.io/chaosmonkey/">Chaos Monkey</a> can help you test your recovery procedures.

One issue that some of the most seasoned practitioners often miss is that all cloud providers have hard limits on their resources that they are able to sell you. After all, they are just running their own data centers, and there are a fixed number of servers that they have on-hand. I have often encountered these limits in practical, seemingly-simple use cases. For instance, I’ve created applications which needed high-memory virtual servers, where the provider didn’t have enough instances to sell us. During the pandemic response, I also discovered that cloud-based email inboxes have <em>hardcoded, technical limits</em> as to the volume of mail they can receive. I had assumed we could simply buy more capacity but this was not the case, requiring a “Rube Goldberg machine” workaround of routing rules to handle the massive increase associated with a national disaster. There is no question that scalability is a huge benefit, <em>until</em> the practical limits become a <em>liability</em> because of your assumptions.

<h2 id="myth-5-cloud-must-be-all-or-nothing">Myth 5: Cloud Must Be All-or-Nothing</h2>

Many organizations assume that the goal is to move everything to a commercial cloud provider.  Both the <a href="https://www.nextgov.com/it-modernization/2017/03/gao-optimize-data-centers-or-lose-them/136416/">Government Accountability Office and Congress</a> have stated that the government needs to “get out of the data center business.” However, this is simply not a realistic goal in the public sector - government couldn’t afford to make such a massive move given their very restricted budgets.

We also must clarify the concept of “legacy systems,” another <a href="http://www.gao.gov/assets/680/677454.pdf">frequent talking point</a>. Most Federal agencies that have been around for more than 30 years still have mainframes, and they’re often still running older programming languages such as COBOL, Fortran, and Pascal. Many major industries in the private sector still use these <em>same technologies</em> - most notably, the banking industry still is heavily dependent on these legacy systems. Regardless of the hype about cloud and blockchain for moving money around, <a href="https://www.wealthsimple.com/en-ca/magazine/cobol-controls-your-money">95% of credit card transactions still use a COBOL system</a>, probably running on a mainframe behind the scenes. These systems are not going away <em>any time soon</em>.

Now these mainframes usually are not dusty old metal boxes that have been taking up an entire basement room for decades. Often, they’re cutting edge hardware that’s incredibly efficient - and even have all the shiny plastic and glowing lights and advanced cooling systems you’d expect to see on a gamer’s desktop computer. Dollar for dollar, modern mainframe systems can be more cost-effective than cloud for comparable workloads over their lifecycle. It’s also worth noting that they are about a thousand times <em>less likely</em> to be attacked or exploited than cloud-based infrastructure.

The code running on these mainframes, on the other hand, is likely to be <em>very old</em>, and it’s almost certainly been written such that it cannot be virtualized or moved to the cloud without rewriting partially or entirely at great expense. Modern programming languages <a href="https://www.davidhaney.io/npm-left-pad-have-we-forgotten-how-to-program/">come with their own risks</a>, so finding a <em>sustainable</em> middle path between the ancient and bleeding-edge is important for a successful modernization effort.

Due to the considerations above, the future of government infrastructure will remain a hybrid, multi-cloud environment - much to the consternation of cloud vendors.

<h2 id="-i-just-know-that-something-good-is-gonna-happen">“… I just know that something good is gonna happen”</h2>

Instead of these myths, the best reason to use cloud is for the unrivaled <em>capabilities</em> that these tools can unlock:

<ul>
  <li>
    Agility: being able to quickly spin up a server to try something new is much easier in the cloud, if you have not already created an on-premise virtualized infrastructure. <a href="https://cloud.gov/">Cloud.gov</a>, an offering from the General Services Administration (GSA) that bundles many Amazon Web Services (AWS) offerings in a government-friendly “procurement wrapper” can make this even easier for agencies.
  </li>
  <li>
    Scalability: the main hallmark of cloud is using this agility to quickly respond to sudden increases in requests to websites and applications. Especially during the COVID-19 pandemic, agencies have taken advantage of this functionality to deal with the dramatic increase in traffic to benefit applications and other services. However, it is critical to note that most cloud services do <em>not</em> scale automatically (another myth covered below).
  </li>
  <li>
    Distributed: most Federal agencies have staff in field offices all over the country, and of course their customers are both at home and abroad. Since the cloud is really just a series of distributed data centers around the world, this can dramatically reduce the latency between the customer and the service. For instance, agencies are using cloud-based virtual private network (VPN) solutions to securely connect their staff to internal networks. Those that have moved to cloud-based email, video chat, and document collaboration tools see an additional speed bump for staying in the same cloud for all of these services.
  </li>
</ul>

Of course, we all know that “cloud is just someone else’s data center,” but the government should not be held back by fear, uncertainty, and doubt from someone else holding their data. Cloud technologies have a huge potential to improve Federal technology, when approached with a full knowledge of the complexity and costs.

Cloud is not a replacement for good management, however. <a href="https://billhunt.dev/blog/2020/12/19/federal-policy-recs/">You can’t buy your way out of risk</a>. Until the government invests in its workforce to make sure that IT can be planned, acquired, implemented, and maintained effectively, we will not see any improvement in the services provided to the American people. Now, Congress just needs to be convinced to <a href="https://www.whitehouse.gov/briefing-room/legislation/2021/01/20/president-biden-announces-american-rescue-plan/">fully fund some of these improvements</a>.

Next week I’ll share <a href="/blog/2021/03/07/cloud-strategy-guide/"><strong>part two</strong></a>, where I will discuss several key strategies for a successful cloud implementation in a government agency.

          
          </p>
          <p>
            <a href="/blog/2021/02/28/cloudbusting/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2021/02/18/login-gov-for-everyone/"up-follow>Login.gov for Everyone!</a></h3>
        </header>
        <div class="post-content">
          
          <p>
            <span class="date">
              2021.02.19
            </span> –
          
            A little over two years ago, I was walking out of the New Executive Office Building by the White House. I immediately ran into <a href="https://twitter.com/RobinCarnahan">Robin Carnahan</a>, who said to me, “Bill, we should be able to provide Login to cities and states.” (If you haven’t met Robin, let me just make it clear for the narrative here that she’s super-smart and anything she says you should just agree with immediately because she knows what she’s talking about.) As soon as I got back to my desk at the Office of Management and Budget (OMB), I started sending out emails to figure out why the General Services Administration (GSA) was preventing this excellent service from being used by smaller governments.

For those of you who don’t know about this hidden gem, <a href="https://login.gov/">Login.gov</a> is a GSA solution to help solve the difficult problem of verifying that a person is who they say they are to receive a government benefit, as well as a solution for logging into government websites.  It was created through the combined efforts of USDS and 18F - the two most prominent digital service teams in all of government - and is in use by many Federal agencies today. Today it provides access to government services for over <strong>27 million people</strong>!

Today, <a href="https://www.gsa.gov/blog/2021/02/18/logingov-to-provide-authentication-and-identity-proofing-services-to-a-limited-number-of-federally-funded-state-and-local-government-programs">GSA has announced</a> that Login.gov is available for use by local and state governments!  (To be clear, I had effectively nothing to do with the actual permission being granted here - sending stern emails had little effect. The victory today belongs entirely to the wonderful, amazing, fantastic team at Login and the bureaucrats who were willing to push to make it happen.)

There are, however, still a few restrictions for city and state use. To be eligible, the government agencies must be using Login for a “federally funded program.” This is an arbitrary addition by GSA that, in my opinion, misinterprets the original intent of the legal authority - but I’m not a lawyer and am no longer responsible for these sorts of policy decisions. I am hopeful that this restriction will be removed in the future and this incredible service will be open to all who want it!

Moreover, as <a href="/blog/2020/12/18/federal-policy-recs/#4-solve-identity-once-and-for-all">I’ve written in the past</a>, it is my hope that OMB will <strong>mandate</strong> the use of Login for all Federal agencies. This is <a href="https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title6-section1523&amp;num=0&amp;edition=prelim">already mandated by law</a>, but OMB is not enforcing the requirement. The most expensive part of the tool is the identity verification step - however, once an identity has been proven, it does not need to be re-proven if the customer wants to use any other service that is using Login. This means that as more organizations sign up for Login, the cost to each decreases. By allowing Federal agencies to maintain their own independent login systems, the costs remain high. Moreover, this presents customers with an inferior experience, as they must sign up for a new account for each website or application.

It’s also important to note that most identity verification behind the scenes is using data sources that the government controls and gives to private companies, who then sell the government back its own data in the verification process at a very high premium. Eventually, it would be smarter to allow agencies to exchange the necessary information themselves, cutting out the middleperson, which would decrease the cost to <em>almost nothing.</em> (Congress, of course, could speed this along too with the right legislation.)

I’ve heard that the Login team has also been working on a pilot to allow customers to prove their identity in-person at a government facility, which has shown to improve the success rates of the verification process. The Department of Veterans Affairs (VA) uses such a process to help Veterans walk through the process of setting up their online accounts right in the lobby of many VA health clinics. The US Postal Service also performed a similar pilot several years ago, where anyone could stop by a post office and have them review their documents, or even let their postal carrier perform the review when they drop off the day’s mail, allowing them to reach almost every single person in the country!

Detractors still complain about the cost of Login.gov, and consider that a reason to not require it, even though the cost would be reduced if it <em>was mandated</em>. Even so, <em>if</em> the Federal government agrees that this is the tool that agencies should be using, then it should be treated like a Public Good - like a library or park. To that end, Congress could pass appropriations dedicated to funding this critical program, for instance as part of <a href="https://www.whitehouse.gov/briefing-room/legislation/2021/01/20/president-biden-announces-american-rescue-plan/">President Biden’s proposal for TTS Funding</a>.

However, I would caution agencies from implementing identity requirements <strong>beyond what is absolutely necessary</strong>! The <a href="https://www.nist.gov/itl/tig/projects/special-publication-800-63">Digital Identity Guidelines from the National Institute for Standards and Technology (NIST)</a> are the baseline that most Federal agencies use; in my personal opinion, they set too high a bar. The government must provide critical services to at-risk and economically disadvantaged groups, and by setting requirements that individuals in these groups cannot meet agencies are not serving people equitably. For instance, the the VA serves Veterans that may be homeless, may not have a credit card, may be partially or fully blind, may have trouble remembering or recalling information, may not have fingerprints, and so on.  Since the standard methods of identity verification and authentication may present an impossible barrier for the very people the VA serves, it is in the best interest of these people to not implement NIST’s high standards as written. (And I told NIST the same thing.)

If you’re a city or state government interested in a world-class identity solution, I’d recommend reaching out to GSA about Login.gov! Even if you don’t meet the requirement mentioned above, it’s definitely worthwhile to getting in touch with GSA anyway - as we’ve learned, policies change every day.

          
          </p>
          <p>
            <a href="/blog/2021/02/18/login-gov-for-everyone/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2021/01/25/presenting-eopbot/"up-follow>Presenting EOPbot</a></h3>
        </header>
        <div class="post-content">
          
            <p>
              <img src="/uploads/2021/01/fedwifi.jpg" class="featured-image">
            </p>
          
          <p>
            <span class="date">
              2021.01.26
            </span> –
          
            If you’re like me, you may be having trouble keeping up with all the new Executive Orders and OMB Memos that the Biden Administration is putting out.  To help, I’ve created a little bot to look for changes on specific pages of the White House website: <a href="https://twitter.com/EOPbot">@EOPbot</a>!

<img src="/uploads/2021/01/fedwifi.jpg" height="200" width="200" />

<p class="banner"><strong>Update 2022.09.11:</strong> I’ve added posts from the Office of Science and Technology Policy (OSTP) and the Office of Personnel Management to EOPbot! I’ve also added RSS Feeds for folks who don’t use Twitter:

<p class="banner"><strong>All Posts:</strong> <a href="https://static.billhunt.dev/eopbot/feed/all.rss.xml">RSS</a>, <a href="https://static.billhunt.dev/eopbot/feed/all.atom.xml">ATOM</a><br />
<strong>Memos &amp; Policies Only:</strong> <a href="https://static.billhunt.dev/eopbot/feed/filtered.rss.xml">RSS</a>, <a href="https://static.billhunt.dev/eopbot/feed/filtered.atom.xml">ATOM</a>

When I worked for the Office of Management and Budget (OMB), I generally had the inside track on most IT policies as they were being drafted. However, I didn’t usually get to see every Executive Order (EO) or presidential action until after they were published. Now that I work for a Federal agency, it’s even harder for me to keep up with all the changes that we have to implement.

And the Biden Administration has been <strong>busy</strong>! In just his first week, President Biden has already issued <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/">31 official actions</a> and <a href="https://www.whitehouse.gov/omb/information-for-agencies/memoranda/">two OMB memoranda</a> - that’s a lot! To help me stay on top of all of these policy changes, I went back to my civic tech roots and created a simple web scraper to monitor for changes to the White House website. Of course, it wouldn’t be civic tech if I didn’t share the resource with everyone, so I started <a href="https://twitter.com/EOPbot">pushing the results to Twitter</a>. I also <a href="https://github.com/krusynth/EOPBot">released the code</a> under an open source license as well.

Since The White House website now runs on Wordpress, it does have <a href="https://whitehouse.gov/feed/">a limited RSS feed for its posts</a>, which includes Executive Orders. However, other actions from the other Executive Office of the President (EOP) offices, such as OMB and OSTP, aren’t “posts” and are not included in that feed.

In the future, a well-staffed communications team could publish these items far easier than I can scrape them, both to the website as posts as well as to official twitter feeds. I’d be happy to hand over the <strong>@EOPbot</strong> account to an official government team to pick up this work if anyone in EOP is interested!

In the meantime, if you find something broken, or if you’d like to contribute an improvement, please <a href="https://twitter.com/krusynth">send me a tweet</a> or <a href="https://github.com/krusynth/EOPBot/issues">open an issue</a>!

          
          </p>
          <p>
            <a href="/blog/2021/01/25/presenting-eopbot/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2020/12/21/ai-ml-rpa-principles/"up-follow>Principles for Automation in Government</a></h3>
        </header>
        <div class="post-content">
          
          <p>
            <span class="date">
              2020.12.21
            </span> –
          
            This article is part three in a <a href="/policy-recs/">series on IT policy recommendations</a>. A PDF of the full recommendations may be <a href="https://billhunt.dev/uploads/2020/12/IT-Policy-Recommendations-2021-2024.pdf">downloaded here</a>.

Artificial Intelligence (AI), Machine Learning (ML), Robotic Processing Automation (RPA)<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>, and other related predictive algorithm technologies <a href="https://www.congress.gov/bill/116th-congress/house-bill/5901/text/enr">continue to gain attention</a>. However, at the moment their promises are far greater than the reality, and instead of successes we continue to see <a href="https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28">the worst of ourselves reflected back</a>. Vendors also continue to oversell the functionality of these tools, while glossing over major expenses and difficulties, such as acquiring and tagging training data.

The Trump Administration, rather than increasing scrutiny and oversight of these technologies, only sought to <a href="https://www.federalregister.gov/documents/2019/02/14/2019-02544/maintaining-american-leadership-in-artificial-intelligence">reduce barriers to its usage</a>. The Biden Administration will need to** create stronger protections for the American people through better governance of the usage of these solutions in government.**

The problem is that humans have written our biases into our processes, and automation only expedites and amplifies these biases. (The book <a href="https://www.amazon.com/dp/B0739MF8VF/">Automating Inequality</a> explains this better than I ever could.) As a technologist, I become concerned when I hear of government agencies implementing these technologies for decision-making, as our unequal systems will only lead to greater inequity. It’s all too easy to “<a href="https://www.propublica.org/article/only-seven-of-stanfords-first-5-000-vaccines-were-designated-for-medical-residents">blame the algorithm</a>” to avoid liability, but it’s who humans create the algorithms.

Simply put, the Federal government cannot have <a href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist">racist chatbots</a>. The government must not exacerbate the problem of <a href="https://www.npr.org/2020/05/12/853934104/minority-owned-small-businesses-were-supposed-to-get-priority-they-may-not-have">minorities not receiving benefits they deserve</a>. And the government should not be using tools that can <a href="https://www.nature.com/articles/d41586-019-03228-6">reenforce existing racism and sexism</a> while <a href="https://www.whitehouse.gov/presidential-actions/executive-order-combating-race-sex-stereotyping/">remaining willfully ignorant of these topics</a>. Yet with all of these failures, we still see organizations running gleefully towards toxic ideas such as <a href="https://theconversation.com/why-big-data-analysis-of-police-activity-is-inherently-biased-72640">predictive policing</a> and <a href="https://www.theatlantic.com/technology/archive/2020/07/defund-facial-recognition/613771/">facial-recognition technology</a>.

Fundamentally, <strong>this is a question of ethics.</strong> Although in government we have extensive ethics laws and regulations in regard to finances and influence, there is almost no actual guidance on ethical practices in the use of technology. And in the U.S. there exists no standard <a href="https://en.wikipedia.org/wiki/Iron_Ring">code of ethics for software engineering</a>, no <a href="https://en.wikipedia.org/wiki/Hippocratic_Oath">Hippocratic Oath</a> for practicing technology. However, we do have a series of regulatory proxies for ethics, in the form of security and privacy requirements aimed to protect the <em>data</em> of the American people.

<img src="/uploads/2020/12/AI.png" alt="A diagram reflecting the balance between human versus computer decision-making and impact to human life and livelihood." />

<em>A diagram reflecting the balance between human versus computer decision-making and impact to human life and livelihood.</em>

By <strong>requiring a series of controls</strong> — not unlike those that we use for IT security — we can increase the safety of the usage of these tools. Similar to the <a href="https://csrc.nist.gov/publications/detail/sp/800-53/rev-5/final">current National Institute of Standards and Technology (NIST) classifications for Low, Medium, and High security systems</a>, artificial intelligence systems should be classified by their impact to people, and the level of automation that is allowed must be guided by the impact. And like the NIST security controls, these must be auditable and testable, to make sure systems are functioning within the expected policy parameters.

For instance, a robot vacuum cleaner presents very little risk of life, but can <a href="https://www.boredpanda.com/robot-vacuum-cleaner-spreads-dog-shit-everywhere/">cause some inconvenience if it misbehaves</a>, so very few controls and human oversight would be required. But automation in the processing for loans or other benefits may disastrously impact people’s finances, so higher controls must be implemented and more human engagement should be required.

Most notably among these controls must be <strong>explainability in decision-making</strong> by computers. When a decision is made by a machine — for instance, the denial of a benefit to a person — we must be able to see exactly <em>how and why</em> the decision was made and improve the system in the future. This is a requirement that <a href="https://ai.google/static/documents/perspectives-on-issues-in-ai-governance.pdf">megacorporations have long railed against</a> due to the potential legal liabilities they may face in having to provide such documentation, but the Administration must not yield to these private interests at the expense of The People.

Another key control will be transparency in the usage of these systems, and all Federal agencies must be required to notify the people when such a system is in use. This should be done both through a Federal Records Notice similar <a href="https://www.federalregister.gov/privacy-act-notices-regs">to the ones required for new information systems</a>, but also on the form, tool, or decision letter <em>itself</em> so that consumers are aware of how these tools are used. Standard, plain language descriptions should be created and used government-wide.

Related to that control, any system that makes a determination, on a benefit or similar, must have a process for the recipient to appeal the decision to an actual human in a timely fashion. This requirement is <em>deliberately</em> burdensome, as it will actively curtail many inappropriate uses in government, since overtaxed government processes won’t be able to keep up with too many denied benefits. For instance, the <a href="https://www.va.gov/decision-reviews/legacy-appeals/">Veterans Benefit Appeals system</a> currently is entirely manual, but has a delay of a year or more, and some Veterans have been waiting years for appeals to be adjudicated; if a system is seeing an unreasonably large number of appeals of benefit denials, that’s a good indicator of a broken system.

Moreover the result of that appeal must become part of the determining framework after re-adjudication, and any previous adjudications or pending appeals should be automatically reconsidered retroactively.

There also exists a category of uses of Artificial Intelligence that the government should entirely prohibit. The most extreme and obvious example is the creation of lethal robots for law enforcement or military usage — regardless of what benefits the Department of Defense and military vendors try to sell us. Although there’s little fear of a science-fiction dystopia of self-aware murderbots, major ethical considerations must still be taken into account. If we <a href="https://www.npr.org/2020/06/01/867532070/trumps-unannounced-church-visit-angers-church-officials">cannot trust even human officers to act ethically under political duress</a>, we certainly cannot expect robots devoid of any empathy to protect our citizens from tyranny when they can be turned against people with the push of a button.

Similarly, the government must also be able to hold private companies liable for their usage of these technologies both in government and the private sector as well. If something fails, the <a href="https://www.congress.gov/bill/113th-congress/senate-bill/2521/text">government legally owns the risk</a>, but that does not mean that private companies should escape blame or penalties. The increase in companies creating self-driving cars will inevitably lead to more deaths, but <a href="https://www.npr.org/2019/03/06/700801945/uber-not-criminally-liable-in-death-of-woman-hit-by-self-driving-car-says-prosec">these companies continue to avoid any responsibility</a>. The <a href="https://www.transportation.gov/AV/federal-automated-vehicles-policy-september-2016">National Highway Traffic Safety Administration’s recommendations on autonomous vehicles</a> do not go nearly far enough, merely making the “request that manufacturers and other entities <em>voluntarily</em> provide reports.”

In short, the government must make a stand to protect its people, instead of merely serving the interests of private companies — it cannot do both.

For further reading, the governments of <a href="https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32592">Canada</a> and <a href="https://cyber.harvard.edu/story/2020-12/bkc-policy-practice-ai-hosts-expert-review-colombias-ai-ethical-framework-focus-youth">Colombia</a> have released guidance on this topic, providing an excellent starting point for other governments.

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      Some of us technologists have referred to RPA as “<a href="https://en.wikipedia.org/wiki/Steampunk">Steampunkification</a>” instead of IT modernization, as the older systems are still left in place while newer tech is just stuck on top, increasing rather than decreasing the technical debt of an organization— much as Steampunks glue shiny gears onto old hats as fashion. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a>
    </li>
  </ol>
</div>

          
          </p>
          <p>
            <a href="/blog/2020/12/21/ai-ml-rpa-principles/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2020/12/19/federal-policy-recs/"up-follow>Reskilling and Hiring for Technology in Government</a></h3>
        </header>
        <div class="post-content">
          
          <p>
            <span class="date">
              2020.12.19
            </span> –
          
            This article is part two in a <a href="/policy-recs/">series on IT policy recommendations</a>. A PDF of the full recommendations may be <a href="https://billhunt.dev/uploads/2020/12/IT-Policy-Recommendations-2021-2024.pdf">downloaded here</a>.

The nature of business is <strong>change</strong> — we move, refine, and combine goods and services and data, which generates <em>value</em> — and this is true both in the public and the private sector. Technology is just one of the ways that we <em>manage</em> that change. Those organizations that do best at managing change are often the best equipped to deal with the relentless pace of transformation within the IT field itself. Government, however, tends to resist change because of misaligned value incentives which prioritize <em>stability *and avoid *risk</em>, though these elements do not necessarily need to be at odds with one another.

Since the Reagan era, government agencies have outsourced more and more IT tasks to contractors and vendors, under the false promise of reduced risk and increased savings for taxpayers. There’s an infamous joke that we’ve done such a good job of saving money through IT over the last decade that we’ve reduced the IT budget of $2 billion to $40 billion. Yet almost all of that spending has gone to private companies, instead of increasing Federal staff and providing needed training, and the government has astonishingly little positive progress to show for it —<a href="https://www.gao.gov/highrisk/improving_management_it_acquisitions_operations/why_did_study"> systems and projects continue to fail</a>. This effort has <em>lobotomized</em> government by eliminating subject matter experts, reducing its ability to manage change, and as a result has greatly increased — rather than reduced — the risk for Federal agencies.

Agencies have tried to “buy their way out” of their risk, by leveraging vendors and IT products to “absorb” the risk. Unfortunately, government doesn’t work that way — agencies are solely responsible for risk, and if something fails, the agency, not the vendor, is the one on the hook for any lawsuits or Congressional hearings that result. <strong>The only practical way for agencies to deal with their risk and begin paying down the government’s massive <a href="https://en.wikipedia.org/wiki/Technical_debt">technical debt</a> is to <a href="https://www.cio.gov/assets/resources/Future_of_Federal_IT_Workforce_Update_Public_Version.pdf">hire and train experts</a> inside of government who can address these problems directly, and begin to facilitate change management.</strong>

In the <a href="https://cloud.cio.gov/strategy/">Cloud Smart strategy</a> OMB states, “to harness new capabilities and expand existing abilities to enable their mission and deliver services to the public faster … instead of ‘buy before build’, agencies will need to move to ‘<strong>solve before buy</strong>,’ addressing their service needs, fundamental requirements, and gaps in processes and skillsets.” Although there has been a major effort to hire and train cybersecurity professionals in government, technology literacy needs to be improved in all job roles. Technology will always be a core function of government, and to be successful, government <em>must</em> have expertise in its core functions; to do otherwise is to deliberately sabotage that success.

Efforts such as <a href="https://18f.gsa.gov/">GSA’s 18F Team</a> and <a href="https://www.usds.gov/">The US Digital Service (USDS)</a> have proven that there is a need for this expertise, and the government must continue and expand on those efforts by teaching agencies “how to fish.” Beyond just these short-term hires via <a href="https://www.chcoc.gov/content/smarter-it-delivery-schedule-hiring-authority">Digital Service/Schedule A</a> and <a href="https://www.opm.gov/policy-data-oversight/hiring-information/direct-hire-authority/#url=Governmentwide-Authority">Cybersecurity/2210</a> to augment staff temporarily, <strong>agencies need to invest in <em>permanently</em> expanding their knowledge, skills, and capacity</strong>.

<h2 id="increase-training-opportunities-for-federal-government-employees">Increase Training Opportunities for Federal Government Employees</h2>

First, there needs to be a** governmentwide approach to increasing training<strong>, starting with **additional funding in the President’s budget dedicated to improving IT skills</strong>. Financial and leave award incentives could also be used to encourage staff to participate in more training outside of their immediate job roles.

The <a href="https://www.cio.gov/programs-and-events/reskilling/">Federal Cybersecurity Reskilling Academy</a> as part of the <a href="https://cloud.cio.gov/strategy/">Cloud Smart strategy</a> was a good start, but didn’t go far enough. It’s impossible to fully train a practitioner in everything they need to know about Cybersecurity — or any other complex technology — in just a few short weeks. A real <strong>apprenticeship program</strong> in the form of <a href="https://www.opm.gov/policy-data-oversight/hiring-information/details-transfers/">agency rotation &amp; detail programs</a> for staff into more IT-mature agencies would have a major impact, by allowing staff to learn skills on-the-job in a hands-on way. Many of these skills are impossible to learn meaningfully from a book or seminar; in general most technical certifications — instead of being required — should be met with skepticism.

Almost all policy decisions today have some aspect of technology involved. To address the <a href="https://www.gao.gov/products/GAO-19-471">rapidly aging Federal IT infrastructure</a> and make smart investments with taxpayer dollars, all of our leaders need to be equipped with knowledge of modern systems beyond just the sales pitches they receive from vendors. Ongoing training in technology must be made a priority and part of every <a href="https://www.opm.gov/policy-data-oversight/senior-executive-service/">Senior Executive Service (SES)</a> performance plan.

<h2 id="create-a-new-it-job-series">Create a new IT Job Series</h2>

Although many technologists have been willing to work for a short term of 2–4 years in government at a massive pay cut just out of a feeling of civic duty, this sort of “holiday labor” is not a sustainable path for long-term success. A new Administration will need to <strong>address the <a href="https://www.govexec.com/workforce/2020/01/report-feds-are-increasingly-interested-leaving-certain-private-sector-jobs/162461/">massive pay disparity for government IT jobs</a></strong>, which acts as a barrier to both hiring and retaining staff. The White House will need to direct the Office of Personnel Management (OPM) to establish a proper IT job series or extend the 2210 CyberSecurity role definition, and create a <a href="https://apps.opm.gov/specialrates/index.aspx">special rate</a> that reduces this gap particularly at the top end of the scale (GS-13 through GS-15).

Ideally this pay should be competitive with the private sector by locale, or as close to the standard rates as possible. And this pay must be made available to staff as they are retrained, <em>not just</em> to outsiders coming in to government with lucrative salaries from the private sector. Without this key step, the work done to reskill our staff will be lost as they use their new skills to find better-paying employment outside of government.

Also, this job series should include not only security personnel, software engineers, and graphic designers, but also non-traditional (but very important) members of government technical teams such as program &amp; product managers, contracting officer representatives (CORs), customer experience experts, and content designers.

<h2 id="leverage-modern-hiring-techniques-to-bring-in-skilled-personnel">Leverage Modern Hiring Techniques to Bring in Skilled Personnel</h2>

Third, agencies must be directed to <strong>aggressively move away from older hiring processes and switch to techniques which evaluate if candidates can actually do the job</strong>. OPM, in coordination with USDS, has already done a lot of work towards this, including <a href="https://www.chcoc.gov/content/draft-general-schedule-qualifications-policy-eo-13932-modernizing-and-reforming-assessment-0">eliminating education requirements</a> and moving to <a href="https://www.govloop.com/usds-opm-test-new-ideas-for-improving-hiring-outcomes/">knowledge-based hiring techniques</a>, but agencies largely have not yet implemented this new guidance. The White House will need to apply more pressure for these changes if agencies are expected to adopt them. Initiatives such as <a href="https://www.f6s.com/launchgrad">Launch Grad</a> and the <a href="https://www.codingitforward.com/civic-digital-fellowship">Civic Digital Fellowship</a> could also provide a pipeline for potential candidates with critical skills into government service.

<h2 id="improving-diversity-in-the-senior-executive-service">Improving Diversity in the Senior Executive Service</h2>

Finally, major improvements must be made to the <a href="https://www.opm.gov/policy-data-oversight/senior-executive-service/">Senior Executive Service</a> (SES) hiring process. These staff represent the senior leaders at Federal agencies, and almost all policy decisions today have some aspect of technology involved. To address the <a href="https://www.gao.gov/products/GAO-19-471">rapidly aging Federal IT infrastructure</a> and make smart investments with taxpayer dollars, all of our leaders need to be equipped with knowledge of modern systems beyond just the sales pitches they receive from vendors.

In addition to increasing critical technical knowledge of these key decision-makers, the lack of diversity of this group has gone woefully unaddressed even <a href="https://www.gao.gov/products/GAO-04-123T">after years of critical reports</a>. Since these SESs are on the boards that hire the other SESs, and many of these leadership roles are filled due to tacit political connections not the candidates’ skills, it is unlikely that the diversity will improve organically from this in-group.

This entire hiring process needs to be reconsidered to level the playing field. The <a href="https://www.opm.gov/policy-data-oversight/senior-executive-service/executive-core-qualifications/">Executive Core Qualifications</a> (ECQs) were a good idea to set a baseline for expertise in senior management, but have largely become an expensive gatekeeping exercise. This has given rise to a cottage industry of writers who simply churn out government resumes to a pricetag of <em>thousands</em> of dollars. I know of very few SES staff who were not either hand-picked for their first SES role or who paid to have their resume written by a professional. This limits these staff to those who can “pay to play” — either with literal dollars or political influence, severely limiting the candidate pool.

On the reviewer’s end, it’s long been known that overtaxed human resources staff are often just <a href="https://ask.fedweek.com/writing-senior-executive-service-ses-resume/">searching for keywords from the job postings</a> in the resumes as a means of first review, which eliminates anyone who may have missed a <em>specific word or phrase</em>. Government expertise and education <em>appears</em> to be given a higher standing than outside experience as well. And after your ECQs have been approved once you don’t need to have them re-reviewed for each job, further narrowing the list of candidates who are considered.

There is no single, easy solution to the systemic problems in this process. Expanding training opportunities for senior General Schedule employees (GS-14 and GS-15) beyond just the outdated and time-consuming <a href="https://www.opm.gov/policy-data-oversight/senior-executive-service/candidate-development-programs/">Candidate Development Program</a> would be a first step. A new Administration could make diversity a key priority in the President’s Management Agenda, setting <a href="https://www.americanprogress.org/issues/race/reports/2011/09/22/10251/a-better-more-diverse-senior-executive-service-in-2050/">goals for hiring and new initiatives for recruiting</a> under the <a href="https://www.chcoc.gov/">Chief Human Capital Officers Council (CHCOC).</a>

<h2 id="in-closing-countering-bias-through-diversity">In Closing: Countering Bias Through Diversity</h2>

Our country is changing, and so is the nature of government. Diversity is critical for all technology roles in government, not just leadership. Addressing <a href="https://www.amazon.com/dp/B0739MF8VF/">systemic bias in the tools</a> that agencies are implementing will require attention from all levels of staff. Our benefit systems must provide services equitably to all, but this will be impossible without acknowledging these biases. However, due to a <a href="https://www.whitehouse.gov/presidential-actions/executive-order-combating-race-sex-stereotyping/">recent Executive Order</a>, training around bias has largely been halted in the Federal government, reducing our ability to tackle this challenge. As the government begins to close gaps around technology skills, it is critical that we’re building a workforce that reflects the people we serve, so that we can better address these issues at their root.

          
          </p>
          <p>
            <a href="/blog/2020/12/19/federal-policy-recs/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2020/12/18/federal-policy-recs/"up-follow>Federal IT Policy Recommendations: 2021-2024</a></h3>
        </header>
        <div class="post-content">
          
          <p>
            <span class="date">
              2020.12.18
            </span> –
          
            This article is part one in a <a href="/policy-recs/">series on IT policy recommendations</a>. A PDF of the full recommendations may be <a href="https://billhunt.dev/uploads/2020/12/IT-Policy-Recommendations-2021-2024.pdf">downloaded here</a>.

<h2 id="executive-summary">Executive Summary</h2>

The work improving technology in government through policy initiatives over the last twelve years has been very successful, however there will always be more work that needs to be done. Today, there are several key steps that the Biden Administration could immediately address and work on over the next four years to continue to build trust and drive maturity in technology across government to “Build Back Better” — not just at the Federal level, but state and local as well. These steps include:

<ol>
  <li>
    Renew the Commitment to Open Data &amp; Transparency
  </li>
  <li>
    Focus on Outcomes, not Box-Checking
  </li>
  <li>
    Drive Customer Experience &amp; Human-Centered Design
  </li>
  <li>
    Solve Identity Once and for All
  </li>
  <li>
    Increase Attention to Small Agencies and
  </li>
  <li>
    Manage Risk through Security
  </li>
</ol>

I’ve spent the last ten years working on civic tech from local to Federal levels, inside and outside of government, and have been excited to see incredible gains in the government’s ability to deliver services to constituents. After the Obama Presidency, the work to drive innovation in government didn’t suddenly stop — the Trump Administration pursued an aggressive agenda of IT Modernization. This included a major effort to update a very large amount of outdated government technology guidance, laying the critical foundation for many modern technology practices and ideas.

From 2017–2019, I served in the Office of Management and Budget (OMB) in the Office of the Federal Chief Information Officer (OFCIO), where I worked on the new <a href="https://cloud.cio.gov/strategy/">Federal Cloud Computing Strategy, ”Cloud Smart.”</a> I designed this strategy to drive maturity across the Federal Government by updating a variety of older, interrelated policies on cybersecurity, procurement, and workforce training. At the time, we had no idea that many of these initiatives, such as the update to the <a href="https://www.whitehouse.gov/wp-content/uploads/2019/09/M-19-26.pdf">Trusted Internet Connections policy</a> (TIC), would be critical to enabling government-wide mission continuity during the COVID-19 response just a few months later.

From the past 4 years spent in government, I have been able to see many opportunities for improvements that did not get as much attention as they deserve. What follows are a few policy areas that I believe would build trust and improve service delivery to the American people. These aren’t all major innovations, but these efforts are needed to <a href="https://krusynth.medium.com/welcome-home-49c5c8146fe0">Move Carefully and Fix Things</a>.

<h2 id="1-renew-the-commitment-to-open-data--transparency">1. Renew the Commitment to Open Data &amp; Transparency</h2>

Before joining the Federal Government, I spent years working for government transparency organizations including the Sunlight Foundation and the OpenGov Foundation. Although those and many other transparency organizations have shut their doors over the last four years, the need for transparency has never been greater.

However, I no longer hold the naive belief that <a href="https://sunlightfoundation.com/2009/05/26/brandeis-and-the-history-of-transparency/">sunlight is the best disinfectant</a>. As it turns out, disinfectant is a better disinfectant, and regularly putting in the work to keep things clean in the first place is critically important. Transparency is an active process, not an end in and of itself — and <strong>care will have to be given to rebuilding</strong> some of the atrophied muscles within government.

<h3 id="share-data-on-the-fight-against-covid-19">Share Data on the Fight Against COVID-19</h3>

First and foremost, to heal the country a new Administration will need to deal with not only the COVID-19 virus, but also the <em>disinformation virus</em>. To do so effectively will require addressing public trust around information quality and availability. The Administration should <strong>focus on providing timely, accurate information</strong> including infection rates from Health and Human Services (HHS), job numbers from the Department of Labor (DOL), housing data from Housing and Urban Development (HUD), and loan data from the Small Business Administration (SBA). By <strong>utilizing the new Chief Data Officers across government</strong> installed as part of the <a href="https://www.congress.gov/bill/115th-congress/house-bill/1770">Open, Public, Electronic and Necessary, (OPEN) Government Data Act</a> signed into law in 2019, the Biden Administration would be able to gather and centralize the critical recovery data. Everyone loves shiny dashboards, but I would instead propose that <strong>sharing raw data</strong> to allow independent analysis would be vastly more valuable than <a href="https://towardsdatascience.com/dashboards-are-dead-b9f12eeb2ad2">Yet Another Dashboard</a>.

<h3 id="revise-the-national-action-plan">Revise the National Action Plan</h3>

My work on the <a href="https://open.usa.gov/assets/files/NAP4-fourth-open-government-national-action-plan.pdf">Fourth National Action Plan for Open Government</a> (NAP4) — and the<a href="https://e-pluribusunum.org/2019/02/22/after-years-of-delays-and-democratic-regression-usa-releases-weak-open-government-plan/"> challenges the Trump Administration faced in delivering this plan</a> — are matters of public record. As we look towards the Fifth National Action Plan, it will be critical to improve engagement with the public and open government groups. Since most of the country has quickly become accustomed to remote collaboration due to the pandemic, I would recommend <strong>hosting a variety of virtual forums beyond the DC area</strong> to maximize input and idea-generation outside of the beltway. In addition to bringing in more stakeholders from across the country, this would also aid in empowering <a href="https://carnegieendowment.org/2020/11/23/is-coronavirus-catalyzing-new-civic-collaborations-for-open-government-pub-83289">grassroots-initiated activities towards anti-corruption practices</a> as well.

I’d also recommend starting this process as early as possible to develop and gain traction around high-quality, ambitious commitments. There are also more than a few initiatives that civil society has proposed over the last decade that are worthy of reconsideration, including <a href="https://github.com/GSA/participate-nap4/issues">these from the NAP4</a>.

<h3 id="revise-agency-open-government-plans">Revise Agency Open Government Plans</h3>

As part of this work, OMB will need to update the long-neglected <a href="https://obamawhitehouse.archives.gov/the-press-office/transparency-and-open-government">Agency Open Government Plans guidance</a>, which has not been <a href="https://obamawhitehouse.archives.gov/sites/default/files/omb/memoranda/2016/m-16-16.pdf">revised since 2016</a>. Although most agencies have updated their Open Government plans since then, more ambitious efforts to publish data are needed. Notably, <a href="https://www.va.gov/OPEN/docs/open_govt_plan.pdf">the Department of Veterans Affairs (VA) have not updated their plan since 2010</a>, even though more scrutiny has been paid to them by Congress during this time. <a href="https://www.va.gov/oig/pubs/VAOIG-14-02603-178.pdf">The VA Inspector General also previously identified</a> that the VA had been actively working to undermine efforts to measure their progress on improving patient wait times, as a result of simply not recording data on the topic. With the new, $5 billion Electronic Health Records (EHR) system being implemented today, it is even more urgent that the VA improve their transparency.

However, <strong>all Federal agencies should be directed to more aggressively and proactively publish data</strong>, instead of just as a response to Freedom of Information Act (FOIA) requests. Throughout the Trump Administration, <a href="https://sunlightfoundation.com/web-integrity-project/monitoring-federal-websites/">key datasets have been removed from government websites.</a> The new Administration can both better tell its story and also build confidence in the American people using government services by <strong>working to restore key data and increasing the volume of information that is actively shared</strong>.

<h3 id="rebuild-the-office-of-science-and-technology-policy">Rebuild The Office of Science and Technology Policy</h3>

The Office of Science and Technology Policy (OSTP), headed by the Federal Chief Technology Officer, was previously the center of open government work under the Obama Administration, but this office and its authority were dramatically reduced over the last four years, with <a href="https://www.vox.com/2017/3/31/15139966/trump-white-house-technology-science-policy">staff cut from 150 to less than 50</a>. As a result, <strong>major reconstitution of OSTP and other offices will need to be done</strong> to drive these efforts.

<h2 id="2-focus-on-outcomes-not-box-checking">2. Focus on Outcomes, Not Box-Checking</h2>

<h3 id="narrow-oversight-focus-to-high-impact-projects">Narrow Oversight Focus to High-Impact Projects</h3>

Transparency goes hand-in-hand with oversight. The Office of Management and Budget is the primary oversight organization within the Executive Branch (other than Inspectors General), and is organized into smaller domain-specific offices. Staff in these program offices act as “desk officers,” focusing primarily on <a href="https://en.wikipedia.org/wiki/Chief_Financial_Officers_Act">the 24 large CFO Act Agencies</a>. For smaller offices, a* *single individual may be tasked with oversight of several agencies’ billion dollar budgets. OMB’s OFCIO is one such smaller office that has been stretched thin in this oversight duty while having to simultaneously fulfill a variety of policymaking roles. However, the primary role of this office is <a href="https://www.law.cornell.edu/uscode/text/44/3602">to oversee technology implementation across government</a> to ensure the success of projects.

Given the few remaining staff, rather than being stretched thin on <a href="https://www.cio.gov/policies-and-priorities/cpic/">meaningless compliance</a>, these resources could be better spent primarily focusing on only the <strong>top five or ten major technology projects in government and making sure that they do not fail<a href="https://www.gao.gov/products/GAO-15-238">in the way we saw happen with Healthcare.gov</a></strong>. Projects such as the State Department’s passport &amp; visa modernization, the Department of Veterans Affairs new EHR system, and other similar initiatives could greatly benefit from closer scrutiny. By investing in hiring subject matter experts with skills in technology and managing massive projects, the government could save taxpayers billions of dollars while simultaneously improving services. OFCIO should also collaborate closely with the Office of Performance and Personnel Management (OPPM) which oversees the <a href="https://www.whitehouse.gov/wp-content/uploads/2018/06/s280.pdf">Customer Experience initiative</a> across government to make sure that these projects also meet the needs of the American people.

<h3 id="restore-and-expand-the-office-of-the-federal-chief-information-officer">Restore and Expand The Office of the Federal Chief Information Officer</h3>

Moreover, OFCIO shares its limited budget with the U.S. Digital Service’s (USDS) core operations via the Information Technology Oversight and Reform (ITOR) Fund, <a href="https://www.meritalk.com/articles/omb-director-defends-cuts-to-it-oversight-budget/">which was slashed dramatically under the Trump Administration</a>. More than just paying for staff salaries, this fund is used to fund a variety of key technology oversight projects, such as the government’s software code sharing initiative, <a href="https://code.gov/">code.gov</a>. Cuts to this fund have caused OFCIO to eliminate programs like pulse.cio.gov, which monitored and evaluated the maturity and security of agency websites. Moreover, this fund is <em>flexible</em> and can be used by OMB to fund interesting technology initiatives at other agencies. The new Administration should <strong>restore the ITOR budget</strong>. It would also be useful to further supplement this fund by taking the step of working with Congress to set <strong>appropriations to ensure the future of OFCIO and USDS</strong>.

Like OSTP, OFCIO has experienced large setbacks. The constant budget cuts and <a href="https://www.politico.com/story/2019/04/22/federal-tech-strategy-spies-cybercriminals-1283773">toxic culture</a> have decimated the office, and most of the talented &amp; passionate subject matter experts I served with have since left. Reversing the course on this office, and <strong>investing in hiring experts</strong> with practical experience in <em>technology in government</em> — not just Silicon Valley thought leadership solutionism — in these offices and beyond will be critical for the success of Federal IT for the next four years. This will improve both the quality of policy that is created as well as the outcomes of IT projects governmentwide.

<h2 id="3-drive-customer-experience--human-centered-design">3. Drive Customer Experience &amp; Human-Centered Design</h2>

Historically the government spends hundreds of millions of dollars on major IT projects. However, very little work is typically done to make sure that the right thing is being built — or if the right problem is even being solved. And sadly, newer systems are not always better systems. However, initiatives on Human-Centered Design (HCD) — a process to engage service recipients as stakeholders in the design and implementation of those services and systems — that were <a href="https://obamawhitehouse.archives.gov/blog/2015/09/04/using-human-centered-design-make-government-work-better-and-cost-less">started under the Obama administration</a> were built upon over the last four years. For instance, common private sector practices like user research and testing were previously considered difficult in government because of review &amp; approval requirements under the Paperwork Reduction Act, but using <a href="https://methods.18f.gov/validate/usability-testing/">streamlined processes</a> and <a href="https://www.usability.gov/how-to-and-tools/guidance/fast-track-clearance-process.html">blanket-permission requests</a> these barriers have largely been eliminated for most agencies. <strong>These efforts need continued attention and support to maintain the momentum.</strong>

<h3 id="drive-commitment-to-human-centered-design-across-omb">Drive Commitment to Human-Centered Design Across OMB</h3>

At OMB, the Office of Information and Regulatory Affairs and the Performance &amp; Personnel Management office worked to institutionalize much of this work over the last four years, including new <a href="https://www.performance.gov/cx/a11-280.pdf">governmentwide Customer Experience (CX) metrics guidance</a> and a related <a href="https://www.performance.gov/cx/">Cross-Agency Priority Goal</a> as part of the President’s Management Agenda. These metrics should be considered table stakes for driving customer experience, and much more work must be done in this area. For instance, every major (and possibly even minor!) <strong>IT project should have CX metrics defined as part of its requirements</strong>, and these should be tracked throughout the life of the project. For existing projects, these should be created retroactively — starting with the highest-impact public-serving systems — with adequate baselines so that agencies don’t just receive an “easy A.” The recent <a href="https://coe.gsa.gov/docs/2020/Customer%20Experience%20Playbook-Nov%202020.pdf">General Services Administration (GSA) Playbook on CX</a> may provide a great starting point for most agencies.

<h3 id="fix-the-definition-of-agile">Fix the Definition of Agile</h3>

Of course, this customer experience work is not a new idea — in fact, this sort of Human-Centered Design is a core tenet of <a href="https://en.wikipedia.org/wiki/Agile_software_development">Agile software development.</a> Unfortunately, the Federal Government has completely missed the forest for the trees on the principles of Agile, and almost all <a href="https://www.congress.gov/bill/113th-congress/house-bill/1232/text">law and regulation</a> focuses entirely on one area: incremental development, delivering software in small, working chunks over time, instead of delivering a full solution at the end of a lengthy development process. However, the real value of Agile is not in these small chunks, but rather in regular testing – both automated as well as having <strong>actual members of the public using the service directly involved in the development process</strong> to give feedback as the project progresses. In this way, teams can make sure their software works and is actually solving problems for people using the service, instead of <em>assuming</em> what the people served want. In the private sector we joke that you’ll have testing either way — would you rather do it before your product launches when you can get ahead of the issues, or after when it’s a public embarrassment?

Currently, agencies are required to report on their major IT investments and state if these projects are developed “incrementally,” <a href="https://obamawhitehouse.gov/sites/default/files/omb/memoranda/2015/m-15-14.pdf">defined in guidance at the depressingly-low rate of once every six months</a>. <strong>OMB could refine their guidance to add additional Agile characteristics, including the requirement that software is tested throughout the development process with real customers.</strong> This alone would dramatically decrease the number of failed projects in government, saving potentially billions of dollars.

<h3 id="fund-great-customer-experience">Fund Great Customer Experience</h3>

However, all of this work requires expertise to be done well, and expertise comes at a cost. Champions such as <a href="https://www.fedscoop.com/white-house-agencies-cxos/">Matt Lira have called for the creation of Chief Customer Experience Officers (CXOs)</a> within agencies, which would be an excellent next step. However, we must not repeat the mistake of the <a href="https://www.congress.gov/bill/115th-congress/house-bill/4174/text">creation of the Chief Data Officer (CDO)</a> roles, where additional funding was not dedicated for these new roles or their staff – as a result this became yet another hat for the CIO to wear at most agencies. <strong>Agencies will need to have increased funding in the President’s Budget to both hire new CX experts as well as to fund contracts to support these efforts CX efforts government-wide.</strong>

<h2 id="4-solve-identity-once-and-for-all">4. Solve Identity Once and for All</h2>

Accurately verifying a person’s identity to <a href="https://pages.nist.gov/800-63-3/">satisfy Federal requirements</a>, as well as creating a secure environment to allow them to login to Federal websites &amp; tools, is a difficult and expensive task for all agencies. This also remains one of the biggest challenges for both agencies and the people accessing government services today. Most agencies have multiple login systems, each specifically tied to an individual service and without sharing information. For instance at the Department of Veterans Affairs until very recently there were nearly a dozen different login systems. Each of these systems would require you to prove that you are who you say you are separately as well.

<h3 id="mandate-logingov">Mandate Login.gov</h3>

Meanwhile, the GSA’s <a href="https://login.gov/">Login.gov</a> is an easy solution to this problem, and has been an overwhelming success for many agency services, including <a href="https://www.usajobs.gov/">USAJobs</a>, the website for most Federal job postings and application processes. Login.gov provides a simple solution to the very expensive problem of checking the identity of a member of the public and allowing them to login to a government website or application — to receive government benefits, register their small business, or any number of other services. This identity-proofing step is typically the most expensive part of the process, requiring the use of independent, private data sources like those used by our national credit bureaus. With Login.gov, once you’re verified on one site you’re verified at them all, so the cost for taxpayers is <em>dramatically</em> reduced.

Although some agencies are starting to move to this platform, a new administration should <strong>mandate all agencies must use Login.gov</strong>, and require them to <strong>provide a transition plan to this service within 5 years</strong>. In fact, usage of Login.gov is <strong>already required by law</strong>, but the law is simply not being followed (<a href="https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title6-section1523&amp;num=0&amp;edition=prelim">6 U.S.C. 1523(b)(1)(D)</a>). Instead of just an <strong>unfunded mandate,</strong> the President’s Budget should include a request for Congress to provide appropriations directly to GSA to fund these efforts to ensure this product is sustainable well into the future.

<h3 id="use-usps-for-in-person-identity-proofing">Use USPS for In-Person Identity Proofing</h3>

At the VA we also learned that many people have trouble with identity proofing over the internet for a number of reasons, including problems with having suitable cameras for capturing information from IDs, issues with people’s memory that preclude standard address verification methods, and other issues. However, we found that people were much more likely to be successful by having their identity validated by humans in-person at VA hospitals. The US Postal Service (USPS) has <a href="https://gcn.com/articles/2013/01/28/usps-pilot-cloud-federal-id-credential-hub.aspx?sc_lang=en">successfully piloted a service to check people’s identity</a> in-person at both USPS locations and at people’s homes using their existing portable tablets used for mail delivery. <strong>By working with Congress to help fund this service</strong>, identity verification could be a solved problem, while also providing a sustainable additional revenue stream for the desperately-underfunded USPS.

<h3 id="share-these-services-with-state--local-governments">Share these Services with State &amp; Local Governments</h3>

Moreover, <strong>these services should be offered to state and local governments</strong>, who are incredibly eager for these solutions, coupled with the expertise of the Federal government. For instance, the same login that you use for USAJobs could be used to login to your local DMV, once again making government easier and friendlier for everyone. To date, GSA leadership has not actively allowed sales to these governments, even though it is <em>explicitly allowed under law</em> and other similar services have been allowed, such as <a href="https://cloud.gov/">Cloud.gov</a>. The White House should direct <strong>GSA to provide this service to any government agency who wants it — and even to the private sector where appropriate!</strong>

<a href="https://www.congress.gov/bill/116th-congress/house-bill/8048/text">Recent bills in Congress</a> have also prioritized security for state and local governments, so it would not be unreasonable to go even further and <strong>work with Congress to set appropriations to provide this identity service</strong> to them as well. Working closely with the <a href="https://www.cisa.gov/">Cybersecurity and Infrastructure Security Agency (CISA)</a>, GSA could turn this from a small project into a national program.

<h2 id="5-increase-attention-to-small-agencies">5. Increase Attention to Small Agencies</h2>

There are nearly a hundred smaller independent agencies that are not situated under the President’s Cabinet, and as a result they are largely ignored. However, they still have critically important missions, and these agencies also interface with the bigger agencies to exchange data, presenting a number of potential security concerns and operational risks. Although a focus on projects and outcomes — not just compliance — is critical, OMB needs to pay more attention to these smaller agencies.

For instance, the U.S. Securities and Exchange Commission is a small independent agency of only 4000 people, but is tasked with protecting investors and the national banking system, as a result of the stock market crash in the 1920s. As such a small agency, they don’t have nearly the budget for IT and cybersecurity of the large agencies. However, since they exchange data with the Department of the Treasury, they act as a backdoor into the larger agency. This sort of attack, by exploiting a softer target to gain access to a more secure one, is extremely common on the smaller scale and will inevitably become a focus for hostile nation-states in the future.

<h3 id="fund-small-agencies-it">Fund Small Agencies’ IT</h3>

These smaller agencies will need additional resources to be able to deal with these threats while also keeping their services up-to-date. OMB can take the much-needed step of** requesting larger IT budgets for these agencies.** Furthermore, to date no small agencies have been selected for <a href="https://tmf.cio.gov/">Technology Modernization Funds</a> — a “loan program” for agencies to fund IT projects — to help them improve their IT. Meanwhile massive organizations such as U.S. Customs and Border Protection (CBP) — who have an annual budget of <em>17 billion dollars *and are not in any way short of money — have received an *additional</em> 15 million dollars from this fund to update their legacy financial systems. Providing access to further funds for smaller agencies would give them an opportunity to improve their systems.

<h3 id="drive-shared-service-use">Drive Shared Service Use</h3>

Shared IT services are even more important for these agencies as well. In many cases the Chief Information Officer (CIO) will wear many hats — acting as Chief Information Security Officer (CISO), Chief Data Officer (CDO), and other roles. To be successful while being stretched so thin means that staff must take advantage of the capabilities of the bigger agencies to help them fill their gaps, such as the <a href="https://www.justice.gov/jmd/cybersecurity-services">Department of Justice’s Security Operations Center-as-a-Service offering</a>. The idea of a “CIO in a Box” for the smaller agencies has been brought up several times, providing information, services, and resources to these organizations. However, very little movement has been made on this initiative and this is <strong>a large opportunity for further work and investment.</strong>

Other shared services, including the aforementioned Login.gov and Cloud.gov also would provide major benefits to smaller agencies, especially if the <strong>President’s budget included additional dedicated funding to GSA for these projects for small agencies</strong>, so that they don’t have to scrape together the money out of their own limited budgets.

<h2 id="6-manage-risk-through-security">6. Manage Risk through Security</h2>

The common theme here is that cybersecurity remains one of the greatest challenges for technology in government today. The Federal Information Security Management Act (FISMA) sets many of the legal requirements for cybersecurity in government, and in practice this has transformed risk management into <em>risk avoidance</em>, reducing the overall risk tolerance for agencies and freezing any interest in trying new things. There is little hope of Congress fixing FISMA in the near future, and the <a href="https://www.congress.gov/bill/116th-congress/senate-bill/4785/text">attempts to date only will make things worse</a>. In the meantime, <strong>the Biden Administration could supplement ongoing initiatives for security automation with additional resources, and implement the resulting best practices as official policy governmentwide.</strong>

<h3 id="continuous-security-authorization-of-it-systems">Continuous Security Authorization of IT Systems</h3>

At the center of IT security in government is the Authorization to Operate(ATO) process. If you’ve ever worked for the government, I’m sure you groaned just having to read that phrase. FISMA requires that for all IT systems, agencies must implement a series of “security controls” — <a href="https://nvd.nist.gov/800-53">measures defined by the National Institute of Standards and Technology (NIST) to enhance security</a>. Now, this is an extremely laborious process, and a new product may take months to meet the requirements of a security review. This process generates a lot of paperwork — enough to stop bullets, but this isn’t very effective for keeping out nefarious attackers. Many agencies only have a three-year cycle of re-assessing products for these security controls — basically only checking to see if the door is locked once every few years. Moreover, the interpretation and implementation of these controls differ wildly between agencies.

Several agencies have started separate pilots to improve the consistency and speed of this process. For instance, some agencies are working to implement a <a href="https://gsablogs.gsa.gov/innovation/2014/12/10/it-security-security-in-an-agile-development-cloud-world-by-kurt-garbars/">“lightweight authorization to operate” (LATO)</a> or a “progressive authorization to operate” process where only a subset of the security controls must be reviewed to begin <em>developing</em> on a platform, with further controls added along the way before launching the application for public use. Others are moving to “continuous authorization,” a concept similar to <em>continuous integration</em> for software testing, by using standard tools to automatically check the various security controls on an ongoing basis — providing real-time visibility to the security of the systems. Still other agencies are working to standardize security plan language, or use natural language processing (NLP) as a means of reviewing paperwork-heavy controls faster. These efforts also relate to NIST’s efforts to standardize controls via a machine-readable structure called <a href="https://pages.nist.gov/OSCAL/">OSCAL</a>, which is now being used by <a href="https://www.fedramp.gov/FedRAMP-moves-to-automate-the-authorization-process/">GSA’s FedRAMP program</a>. Some of these efforts were previously being replicated via the CIO Council, but with the exodus of OFCIO staff efforts have stalled out. These efforts should be <strong>spread across government via additional funding, staffing, and more pilots</strong>.

<h2 id="conclusion">Conclusion</h2>

These are just a few of the policy areas that need attention in technology in government. There are still other agency-specific projects that need further attention that I haven’t covered here. However, these specific areas of focus will continue to build back better technology in government, and equip us with the necessary tools for the next decade or two.

          
          </p>
          <p>
            <a href="/blog/2020/12/18/federal-policy-recs/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2020/12/11/programming-tests/"up-follow>Hiring and Programming Tests</a></h3>
        </header>
        <div class="post-content">
          
          <p>
            <span class="date">
              2020.12.11
            </span> –
          
            I don’t mean to call anyone out, but I want to talk about programming tests in hiring and contracting. <em>Stop doing them.</em>

This post originally appeared as <a href="https://twitter.com/krusynth/status/1337397081019969537">a thread on my Twitter
account</a>.
I’ve reposted it here for posterity with additional context.

I understand that people want to assess whether or not someone is capable of doing the job at hand.  The problem is that every engineer, no matter how senior, is learning on the job, EVERY DAY. All of us lookup solutions on the internet, all the time.

Your assumption of what should be “baseline knowledge” for one person is based on your own experience. If you learned programming in college, a bubble sort algorithm is probably just muscle-memory by now; for the rest of us, it’s completely irrelevant knowledge.

It also has nothing to do with 99.9999% of jobs. Unless you’re working on some bleeding-edge optimization for a major, that sort of fiddly info is way less relevant that principles and practices. It’s just a great way of showing your biases towards “traditional” candidates.

The worst interview a company ever gave me was to implement a hashing algorithm. I’ve been writing code for 35 years, I’ve never had to do this manually. I failed. It also told me the company didn’t know what to ask me, I immediately withdrew my application.

Tech isn’t about algo knowledge. Bad news to my younger-self: it’s also not about passion. It’s about knowing how to solve problems. Instead of coding exercises here are a few ways to figure out if someone will be a match for the job you’ve got.

In short: don’t ask questions that have a single, expected answer. If you know what the answer is, you’ve created a knowledge-based test - and just like with authentication, you’ve created a bad one.

<ul>
  <li>
    Ask them about a problem they’ve solved recently, have them outline the steps they went through.
  </li>
  <li>
    Ask them about a piece of technology that has made their life easier in some way. Whether it’s a build tool or kitchen gadget, how does this relate to what we do?
  </li>
  <li>
    Ask them what new tools they are excited about, and what makes their life as a developer better? (I specifically avoid saying “fun” here, because working for a paycheck not passion is a perfectly valid reason to be a technologist.)
  </li>
</ul>

If you want to hire senior developers:

<ul>
  <li>
    Ask them about building for audiences that are not like them? How do we create solutions for inclusion?
  </li>
  <li>
    Ask them about why they chose to <em>not</em> use a piece of technology. How did they evaluate it? Cost, maturity, stability, community?
  </li>
  <li>
    Ask them what makes a good culture for a team.  What makes a team productive and empowered?
  </li>
  <li>
    h/t <a href="https://twitter.com/justgrimes">@justgrimes</a>: Ask them to explain how the internet works. Details don’t matter, you want to see if they can read a room and communicate to the level of their audience.
  </li>
  <li>
    My favorite EQ question is “what’s the last good thing you’ve read.” Book/blog/T&amp;Cs/etc. I always add the answers to my reading list - but also high EQ people will usually reflect the question and ask you back. (Unless they’re nervous, so DON’T go on this alone!)
  </li>
</ul>

Here are a few other ideas I received on Twitter:

<ul>
  <li>
    via <a href="https://twitter.com/abbeysuekos">@abbeysuekos</a>: “I’m also starting to get into questions about how people work with those above them (managers/leaders/executives) and those below them (ICs). There are never enough ?s about how you treat people with less power than you… I love questions about projects that didn’t go well. Plenty of good candidates will struggle or even get defensive, and that’s a flag for me. Important to handle the framing carefully and create an explicit safe space, but when done well it’s golden.”
  </li>
  <li>
    via <a href="https://twitter.com/HimalMandalia">@HimalMandalia</a>: “Had an interesting experience with a tech test years ago. Turned out it was one I’d done already, so told them and said “how about instead I show you and talk through what I’m working on at my current place?” They agreed. So did just that. Got the job.”
  </li>
</ul>

<em>Do you have other questions you use to help identify talented candidates, without jumping through programming test hoops? <a href="https://twitter.com/krusynth/status/1337397092457865216">Tell me about it here!</a></em>

          
          </p>
          <p>
            <a href="/blog/2020/12/11/programming-tests/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    

      
      

      <article class="post-multiple">
        <header class="post-header hoverable">
          <h3 class="post-title"><a href="/blog/2020/11/09/welcome-home/"up-follow>Welcome Home</a></h3>
        </header>
        <div class="post-content">
          
          <p>
            <span class="date">
              2020.11.09
            </span> –
          
            I see many of my former technology-colleagues now suddenly eager to
return to government- or join for the first time- and I’m very excited
to work with you all again! That being said, here are a few thoughts
from someone who stuck around for the hard parts over the last 4
years.

<p class="banner">Update February 6th, 2021: This little post has gotten way more attention than I ever could have expected! If you’d like to show everyone that you also want to <strong>Move Carefully and Fix Things</strong>, I’d like to send you a sticker <strong>for free</strong>! <a href="/move-carefully/">Here’s how to get yours!</a>

<p class="banner">Update February 14th, 2021: This post is now a <a href="//billhunt.dev/uploads/2021/02/welcome-home-zine.pdf">free downloadable print-and-fold zine</a>! You can find folding <a href="#instructions-for-the-zine">instructions at the bottom of this page.</a>

This post originally appeared as <a href="https://twitter.com/krusynth/status/1325804228426805248">a thread on my Twitter
account</a>.
I’ve reposted it here for posterity with additional context. This was
originally a very short thread, but if you want to delve deeper into
these topics, I highly recommend reading <a href="https://twitter.com/cydharrell">Cyd
Harrell</a>’s
fantastic book, <a href="https://cydharrell.com/book/">A Civic Technologist’s Practice
Guide</a>

<ol class="spaced-list">
  <li>
    “Move fast and break things” failed. As a result, we inherited a
lot of fast-moving broken things. Sustainability is the most important
principle in government tech today. <strong>“Move carefully and fix
things.”</strong>
  </li>
  <li>
    “Build with, not for” -
<a href="https://linktr.ee/buildwith">Cuán McCann</a>

    <em>(that one is still the most important and gets its own tweet)</em>

    Note: Cuán’s talk at CFA Summit in 2014 begins with “At the
 risk of creating a massive existential crisis…” and the following
 five minutes created one for me. It completely changed how I look at the
 world and approach The Work.

    <iframe width="560" height="315" src="https://www.youtube.com/embed/sbqNkz_mjng" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
  </li>
  <li>
    Technology is <em>almost never</em> the solution to the problem. You need
a deep understanding of culture, policy, budget, acquisitions, etc. to
be successful. We don’t need <strong>ANY</strong> more shiny new websites or
hackathons. Your first year should be spent understanding the
systems.
  </li>
  <li>
    Fam, choose boring tech over shiny. Those mainframes and COBOL still
work just fine after 50 years of service. Those React apps you’re
writing are legacy before they launch, at a hundred times the cost, and
no one can run them when you leave - making them abandonware.
  </li>
  <li>
    Government doesn’t need disruption, or even innovation. Many of us
who came in as “innovators” are now the career bureaucrats just
keeping the place from burning down. Listen to our expertise and work
with us.
  </li>
  <li>
    People don’t want to hear this, but… this isn’t a job for
tourists. Building relationships to cause change takes time. If people
know you have one foot out the door, they’re not going to trust you.
Think about what you’re willing to sacrifice before signing up.
  </li>
</ol>

That all being said… Welcome Home. I’m looking forward to
collaborating with you all soon.

<h2 id="instructions-for-the-zine">Instructions for the Zine</h2>

<p class="featured"><img src="//billhunt.dev/uploads/2021/02/zine-instructions.png" alt="Folding instructions for the zine" />

<p class="featured">Once folded, the outside should have Welcome Home on both the front and back, and the first pages upon opening should be 2 and 3.

          
          </p>
          <p>
            <a href="/blog/2020/11/09/welcome-home/" class="btn"up-follow>Read This</a>
          </p>
        </div>
      </article>
    
  </div>
  <!-- Pagination links -->
  <div class="pagination">
    
      <a href="/posts/" class="previous btn" title="Previous Page" up-follow>
        ◀
      </a>
    
    <span class="page-number ">
      2
    </span>
    
      <a href="/posts/3/" class="next btn" title="Next Page" up-follow>▶</a>
    
  </div>
</section>


    </div>
<footer class="page-footer">
  <div class="webring">
    <script src="https://pitwebring.billhunt.dev/webring.js"></script>
    <script>showWebring(true);</script>
  </div>

  <div class="webring">
    <div class="webring-title">
      Member of the <a href="https://webring.obeythesystem.com/" rel="nofollow">Obey the System Webring</a>.
    </div>
    <nav class="webring-nav">
      <ul class="webring-links">
        <li><a href="https://webring.obeythesystem.com/page?=previous" rel="nofollow">← previous</a></li>
        <li><a href="https://webring.obeythesystem.com/page?=next" rel="nofollow">next →</a></li>
      </ul>
    </nav>
  </div>

  <div class="oldschool-buttons">
    <a href="https://pitwebring.billhunt.dev/" class="old-button" title="Public Interest Tech Webring"><img src="/assets/images/buttons/pitwebring-88x31.gif" alt="" aria-hidden="true"></a>
    <a href="https://webring.obeythesystem.com/" class="old-button" rel="nofollow"><img src="https://webring.obeythesystem.com/ots_webring_button_1.gif" alt="OTS Webring Button"></a>
    <span class="old-button"><img src="/assets/images/buttons/human-88x31.gif" alt="Human-Made - No AI"></span>
    <a href="https://jekyllrb.com/" title="Built With Jekyll" class="old-button"><img src="/assets/images/buttons/jekyll-88x31-ani.gif" alt="" aria-hidden="true"></a>
    <a href="https://archive.org/download/netscape-navigator-4.0.4/netscape-navigator-4.0.4.png" class="old-button" title="This links to an image of the Netscape install CD"><img src="/assets/images/buttons/netscape3-88x31-ani.gif" alt="Get Netscape 3.0"></a>
  </div>
</footer>
</body>

</html>
